[{"content":"std::any vs any_ref 众所周知, std::any是一个类型擦除的容器. 相比void*的, 它的主要区别就是:\nany_cast会保证类型安全. 有明确的所有权语义, 会自己管理被容纳对象的析构, 拷贝等操作. 而void*的所有权语义不明. 非所有权的类型擦除引用 如果我们把上述的第二点改为明确的无所有权语义, 那就得到了any_ref. 类似于std::function和std::function_ref的区别.\n不过, C++标准库中目前还没有any_ref. 在一些第三方库中能见到.\n实现any_ref any_ref的实现要比std::any简单很多, 因为不需要管理对象的生命周期, 实际上可以看做是void*的一个简单wrapper. 相比之下, std::any需要一个类似虚表的结构, 存一些函数指针, 用于析构, 拷贝, move等操作. 一般来说, any_ref只需要存一个void*指针, 和一个用来辨别类型的变量.\n无RTTI实现 如果使用RTTI, 那么只需要对比构建时和cast时的typeid即可. 但为了性能等原因, 如果不使用RTTI, 能不能实现? 答案是肯定的, 只需要利用inline函数或变量地址的唯一性.\nAn inline function or variable shall be defined in every translation unit in which it is odr-used and shall have exactly the same definition in every case (6.2). \u0026hellip;\u0026hellip; An inline function or variable with external linkage shall have the same address in all translation units.\n\u0026ndash; C++17 specification n4713, §10.1.6\n例如, 我们可以使用一个inline的变量模版, 这个模版若用相同的地址单态化, 即使是在不同的编译单元(TU)内, 产生的变量也会具有相同的指针地址. 反之, 如果用不同的类型单态化, 变量地址也会不同. 利用这一点就能实现any_refcast时的类型验证.\n这里直接给出一个简单的实现:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #include \u0026lt;stdexcept\u0026gt; #include \u0026lt;type_traits\u0026gt; namespace detail { template\u0026lt;typename T\u0026gt; inline int any_ref_helper{}; } // namespace detail class AnyRef { public: template\u0026lt;typename T, // Prevent shadowing the copy constructor typename = std::enable_if_t\u0026lt;!std::is_same_v\u0026lt;AnyRef, std::remove_cv_t\u0026lt;T\u0026gt;\u0026gt;\u0026gt; \u0026gt; AnyRef(T\u0026amp; val) noexcept : data_(const_cast\u0026lt;void*\u0026gt;(static_cast\u0026lt;const void*\u0026gt;(\u0026amp;val))), type_ptr_(\u0026amp;detail::any_ref_helper\u0026lt;T\u0026gt;) {} template\u0026lt;typename T\u0026gt; T\u0026amp; cast() const { const auto pT = \u0026amp;detail::any_ref_helper\u0026lt;T\u0026gt;; if (type_ptr_ == pT) { return *static_cast\u0026lt;T*\u0026gt;(data_); } throw std::runtime_error(\u0026#34;Bad type!\u0026#34;); } template\u0026lt;typename T\u0026gt; T* cast_if() const noexcept { if (type_ptr_ == \u0026amp;detail::any_ref_helper\u0026lt;T\u0026gt;) { return static_cast\u0026lt;T*\u0026gt;(data_); } return nullptr; } private: void* data_; const int* type_ptr_; }; inline int any_ref_helper作为上述的变量模版. 构建any_ref时, 成员type_ptr_记录了此模板以原对象的类型实例化后的地址. cast()时, 检查以目标类型和原类型实例化的any_ref_helper地址是否相同. 如果相同, 前后类型一致. 否则类型不一致.\n注意, 构建函数用一个SFINAE禁用了以AnyRef为参数(即指向另一个AnyRef)的构建, 否则会导致AnyRef无法拷贝构建. (由于AnyRef是一个非所有权引用, 因此它应当以拷贝传递/值传递, 类似std::string_view)\n跨编译单元行为 为了测试上面的AnyRef, 如果我们写一个简单的测试程序, 只有一个main.cpp, 那么显然可以work, 这种情况下any_ref_helper\u0026lt;T\u0026gt;只有单个定义, 加不加inline都没区别.\n有趣的部分在于, 如果在不同编译单元, 甚至跨动态链接边界, 分别使用AnyRef的构建和cast, 是否能如期达成类型安全? 毕竟这种类型擦除的主要意义就在于跨API, 跨编译单元, 用于减少编译头文件依赖, 加快编译, 统一API处类型等目的. 如果只在单个编译单元内部使用它, 属于是脱裤子放屁.\n回顾上文引用的C++标准段落, 单个程序(program)中, 一个inline对象在不同编译单元的多个定义必定有相同的地址.\n但是:\n如果这些编译单元最终一起被静态链接到一个程序中, 那么它们应当是属于单个program, 因此地址的唯一性成立. 如果一些编译单元最终成为一个动态链接库(DSO), 那么原则上这个DSO应当是一个单独的program, 和调用它的程序独立. 因此, 问题主要在于动态链接. 这里的bottomline是, C++标准不能保证各个平台/编译器上inline地址唯一性能够跨动态链接成立. 但是, 不同的平台对动态链接的实现不同, 因此具体行为可能存在差异.\n总之关键在于: inline对象在不同编译单元的地址唯一性, 在不同编译/链接环境和平台上, 具体行为如何?\n测试程序 我们为AnyRef写一个简单的跨TU测试项目.\n项目中定义一个库和一个主程序. 库导出一个函数, 参数为AnyRef. 而主程序会管理被引用的对象, 把它用AnyRefwrap起来, 传给库的函数.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // lib.h: #include \u0026#34;any_ref.hpp\u0026#34; #if defined(MYLIB_SHARED) # if defined(_WIN32) # if defined(MYLIB_SOURCE) # define MYLIB_EXPORT __declspec(dllexport) # else # define MYLIB_EXPORT __declspec(dllimport) # endif # else # define MYLIB_EXPORT __attribute__((visibility(\u0026#34;default\u0026#34;))) # endif #else #define MYLIB_EXPORT #endif // Assumes str_ref is a const string ref MYLIB_EXPORT void lib_fn(AnyRef str_ref); 注意头文件中使用了API导出宏, 保证作为动态库时能正确导出符号.\n1 2 3 4 5 6 7 8 9 // lib.cpp: #include \u0026#34;lib.h\u0026#34; #include \u0026lt;string\u0026gt; #include \u0026lt;cstdio\u0026gt; void lib_fn(AnyRef str_ref) { std::puts(str_ref.cast\u0026lt;const std::string\u0026gt;().c_str()); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // main.cpp #include \u0026lt;string\u0026gt; #include \u0026#34;lib.h\u0026#34; #include \u0026lt;iostream\u0026gt; int main() try { const std::string str {\u0026#34;Hello!\u0026#34;}; AnyRef ref{str}; std::cout \u0026lt;\u0026lt; ref.cast\u0026lt;const std::string\u0026gt;() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; lib_fn(ref); } catch (std::exception\u0026amp; ex) { std::cout \u0026lt;\u0026lt; ex.what() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } 最后是项目的CMake定义, 通过-DBUILD_SHARED_LIBS=\u0026lt;0/1\u0026gt;可选择mylib是编译为静态库还是动态库.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # simple CMakeLists.txt: cmake_minimum_required(VERSION 3.20.0) project(anyref VERSION 0.1.0 LANGUAGES CXX) set(CMAKE_CXX_STANDARD_REQUIRED) set(CMAKE_CXX_STANDARD 17) set(CMAKE_CXX_EXTENSIONS OFF) add_compile_options(\u0026#34;$\u0026lt;IF:$\u0026lt;CXX_COMPILER_ID:MSVC\u0026gt;,/W4,-Wall;-Wextra;-pedantic\u0026gt;\u0026#34;) add_library(mylib lib.h lib.cpp any_ref.hpp) # --- For export macros get_target_property(mylib_type mylib TYPE) if(mylib_type STREQUAL SHARED_LIBRARY) target_compile_definitions(mylib PUBLIC MYLIB_SHARED) endif() target_compile_definitions(mylib PRIVATE MYLIB_SOURCE) # --- add_executable(anyref main.cpp) target_link_libraries(anyref mylib) 如果程序如期运行, 那么主程序中lib_fn()应输出\u0026quot;Hello!\u0026quot;. 否则将输出\u0026quot;Bad type!\u0026quot;.\n静态链接 当我们使用静态链接(-DBUILD_SHARED_LIBS=0)编译并运行测试程序, 不出意外, 在各个平台都测试成功. 程序输出了两次\u0026quot;Hello!\u0026quot;.\n动态链接 这里我们先给出结果:\n(TODO: 等我有空了把macOS和MinGW补上)\nWindows 11, MSVC 结果为失败. 通过debugger或手动print能看出, inline变量any_ref_helper在主程序和动态库中的地址确实不同.\nLinux, GCC, glibc 实际测试平台是Fedora 42 和 Ubuntu 20.04. 编译器是GCC 15 和 GCC 9.\n结果为成功.\nLinux, GCC, musl 测试平台是Alpine Linux, GCC 14.\n结果为成功.\nLinux, Clang, glibc 实际测试平台是Fedora 42 和 Ubuntu 20.04. 编译器是Clang 20 和 Clang 12.\n结果为成功.\nLinux, 但-fvisibility=hidden Clang 结果均为失败. 所有 GCC 结果仍为成功. 结果解读 Linux 用nm查看编译出的二进制文件, 可以看到符号导出情况:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 略去了无关的符号 # Clang: $ nm -CD libmylib.so 0000000000000380 T lib_fn(AnyRef) 0000000000003044 V detail::any_ref_helper\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026gt; $ nm -CD anyref U lib_fn(AnyRef) 0000000000403194 V detail::any_ref_helper\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026gt; # Clang, -fvisibility=hidden: $ nm -CD libmylib.so 0000000000000380 T lib_fn(AnyRef) $ nm -CD anyref U lib_fn(AnyRef) # GCC: $ nm -CD libmylib.so 0000000000000440 T lib_fn(AnyRef) 0000000000003044 u detail::any_ref_helper\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026gt; $ nm -CD anyref U lib_fn(AnyRef) 0000000000403194 u detail::any_ref_helper\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026gt; # GCC, -fvisibility=hidden: $ nm -CD libmylib.so 0000000000000440 T lib_fn(AnyRef) 0000000000003044 u detail::any_ref_helper\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026gt; $ nm -CD anyref U lib_fn(AnyRef) 0000000000403194 u detail::any_ref_helper\u0026lt;std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026gt; 根据man nm:\n\u0026ldquo;V\u0026rdquo;, \u0026ldquo;v\u0026rdquo;: The symbol is a weak object. When a weak defined symbol is linked with a normal defined symbol, the normal defined symbol is used with no error. When a weak undefined symbol is linked and the symbol is not defined, the value of the weak symbol becomes zero with no error. On some systems, uppercase indicates that a default value has been specified.\n\u0026ldquo;u\u0026rdquo;: The symbol is a unique global symbol. This is a GNU extension to the standard set of ELF symbol. For such a symbol the dynamic linker will make sure that in the entire process there is just one symbol with this name and type in use.\nClang 可以看出, Clang编译出的二进制中, 动态库和主程序均将any_ref_helper导出为一个weak symbol.\n来自多个链接单元(这里就是我们测试的库mylib和主程序anyref)的同名weak symbol, 在(动态)链接时会统一选用其中的一个(一般是按顺序的第一个. 如果存在一个同名的strong symbol, 就总是选择strong symbol).\n对于定义为inline的对象, 只要保证在各处的定义相同, 这么做就相当于使它们有了统一的定义, 且均指向其中某一个链接单元内的实例. 例如在我们的程序中, 如果动态链接下最终选择了libmylib.so中的weak symbol, 主程序也会使用来自libmylib.so的any_ref_helper定义.\n(需要注意一点, 显然只有经过单态化后, any_ref_helper\u0026lt;T\u0026gt;才可能被导出为symbol, 不然它只是一个模板. 在我们的测试项目中, any_ref_helper只以const std::string作为模板类型被单态化了, 且被定义了2次, 分别在mylib和主程序中. 因此, 链接时可能选择其中的任意一个.)\nGCC 根据上面引用的man page, GCC则是使用了一个非标准ELF符号类型, 也就是nm输出的\u0026quot;u\u0026quot;. 这种符号专门用于保证整个进程中符号所代表对象的唯一性.\n可以看到, 测试的动态库和主程序中均含有这种类型的symbol对应any_ref_helper. 因此, 链接时能确保两者引用的any_ref_helper是同一个对象, 具有相同的地址.\n-fvisibility=hidden 众所周知, Linux下大部分编译器在编译动态库时的默认设置都是导出所有具有external linkage的对象. (参看: https://gcc.gnu.org/wiki/Visibility)\n利用选项-fvisibility=hidden, 可将默认的符号可见性设为不可见, 除非用__attribute__((visibility(\u0026quot;default\u0026quot;)))特别标注为需要导出. 这样做后的行为就和Windows平台上类似了.\n在我们的例子中, Clang由于any_ref_helper是external linkage, 且默认visibility为可见, 就将它导出为了一个weak symbol. 而当我们启用-fvisibility=hidden后, Clang就不再导出这个weak symbol了, 因而主程序和动态库会各自使用自己内部的any_ref_helper, 测试结果失败.\n而对于使用了特殊符号\u0026quot;u\u0026quot;来实现inline唯一性的GCC来说, visibility设置就没有影响了, 因为这种symbol只是用于确保唯一性, 不应受visibility影响.\nWindows Windows的PE可执行格式中, COMDAT用于合并多个编译单元内的同一inline对象, 保证它们的唯一性, 即COMDAT folding.\n但是, 这个合并仅作用于组成单个PE文件的多个编译单元, 而DLL文件算作一个单独的module, 在编译链接DLL时, 它内部的COMDAT区域就已经固定. 运行时动态链接该DLL时, 不会再将它的COMDAT与调用程序的COMDAT合并.\n因此, 对于我们的测试程序, mylib.dll中的any_ref_helper和主程序中的并不是同一个对象, 而是属于各自内部, 具有不同的地址, 所以测试失败.\n导出符号 如果我们需要确保唯一性的inline变量只是一个普通变量, 并不是一个会以任意类型单态化的模板, 那么解决方法就是仅在一个DLL导出这个变量(声明为__declspec(dllexport)), 其它地方, 包括调用这个DLL的程序或其它DLL, 均声明为__declspec(dllimport).\n但是, AnyRef中使用的inline变量模板无法提供所有可能类型的单态化, 并不适用这个做法.\n结论 简而言之,\nany_ref的非RTTI实现需要依赖inline对象的地址唯一性, 但这个唯一性只对单个\u0026quot;程序\u0026quot;保证. 一般而言, 动态链接库是一个单独的可执行image. 但是, 在一些平台/编译器上, 存在一些机制能够跨动态链接边界\u0026quot;打洞\u0026quot;, 提供一些额外的保证. ","date":"2025-01-09T00:00:00Z","permalink":"https://kya8.github.io/p/any_ref-w/o-rtti/","title":"any_ref w/o RTTI"},{"content":"C语言编程中一个常见的practice是将某个struct的definition隐藏, 仅通过指针使用它, 而具体的定义放在一个单独的TU之中, 叫opaque struct. 这种做法的目的一般是为了隐藏struct中的成员, 作为加速编译的隔离手段, 并且还能保证ABI稳定性(因为API只有指针).\n在C++中, 当然也可以用C风格的opaque struct, C++并不阻止你这么做, 但通常的做法是用PIMPL, 方法也是类似的.\n例如, 我们有一个C风格的库libfoo:\n1 2 3 4 5 6 7 8 9 10 // foo.h typedef struct FooCtx FooCtx; FooCtx* foo_create_context(); void foo_destroy_context(FooCtx*); int foo_some_function(FooCtx*); // foo.c // 包含FooCtx和上述函数的定义 使用者只需要拿着这个FooCtx*的handle, 不需要关心它内部是什么.\n避免动态内存分配 常见的opaque struct或者PIML做法, 免不了动态内存分配, 因为FooCtx的size在头文件里未知. 有没有什么办法可以绕过这个要求? 作为C/C++程序员, 总是对动态内存分配比较敏感. 有些场景, 比如某些嵌入式平台还没有一般的动态分配可用.\n答案是可以, 其实就是把FooCtx放在栈上, 用一段栈上的buffer提供存储空间.\n1 2 3 4 5 6 7 8 9 10 11 #define FOO_CTX_SIZE /*...*/ #define FOO_CTX_ALIGNMENT /*...*/ typedef struct FooCtxStorage { alignas(FOO_CTX_ALIGNMENT) unsigned char buf[FOO_CTX_SIZE]; } FooCtxStorage; FooCtx* foo_init_storage(FooCtxStorage* buf); void foo_finish(FooCtx* buf); // cleans up additional resources held by FooCtx, no need to free memory. int foo_some_function(FooCtx*); 显然, FooCtxStorage::buf需要能够装下FooCtx, 并满足内存对齐要求. 这里用了alignas, 如果没有C11, 也可以把FooCtxStorage换成一个union, 加入一个member, 用于确保buf的对齐.\nfoo_init_storage用于在已有的一段缓存上创建一个FooCtx, 并且返回所创建对象的指针. 其它函数只接收FooCtx*作为参数. foo_finish用于释放FooCtx可能管理的资源, 但不需要释放它本身占用的存储, 因为存储是由外部提供.\n这个方法使用时需要先在栈上声明一个FooCtxStorage(当然实际上放在哪里都行), 然后用一个初始化函数获得创建好的FooCtx*, 有两个变量, 需要一致. 而且, 如果对象被move, 还需要保持指针和storage对象同步. (当然, 可以提供专门的move/copy函数避免错误)\n编译期确保大小和对齐 在对应的foo.c的TU里, 我们可以用一些静态assert确保FOO_CTX_SIZE和FOO_CTX_ALIGNMENT确实符合FooCtx的定义.\nStrict aliasing 很遗憾, 实际上这个方法仍然是违反strict aliasing rule的, 因为buf的实际类型是char数组, 且永远不会改变, 把一个FooCtx给memcpy进去也没用. foo_init_storage必定会把buf这片区域当做FooCtx来访问, 就算传void*也没区别, 因此这实际是UB.\n(注意, 用char*访问FooCtx可以, 但反过来不行)\nInline PIMPL A.K.A. fast PIMPL, 也就是不需要经过动态内存分配的PIMPL. 原理上和上面的方法类似, 但由于C++提供了placement new和std::launder, 可以非UB地实现. (这里假设读者已经知晓PIMPL的一般用法.)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // foo.h class Foo { public: Foo(); ~Foo() noexcept; // 有需要的话, 声明(或delete)copy和move // 其它method... private: struct Impl; static constexpr int impl_alignment = /* write it down, or just use max_align_t if no extended alignment */; static constexpr int impl_size = /* .. */ alignas(impl_alignment) unsigned char buf[impl_size]; //Impl* handle; //这一项可以不要, 省掉一点空间, 换成下面的函数. Impl* get_impl() noexcept; } // foo.cpp中的内容 struct Foo::Impl { //... } static_assert(Foo::impl_size \u0026gt;= sizeof(Foo::Impl)); static_assert(Foo::impl_alignment \u0026gt;= alignof(Foo::Impl)); Foo::Foo() { // 如果有handle, 就这时候记录它. // handle = new(buf) Impl{}; // 没有的话, 直接new, 丢掉指针, 一会用std::launder找回来. new(\u0026amp;buf[0]) Impl{}; } Foo::Impl* Foo::get_impl() noexcept { return std::launder(reinterpret_cast\u0026lt;Impl*\u0026gt;(\u0026amp;buf[0])); } Foo::~Foo() noexcept { get_impl()-\u0026gt;~Impl(); } 创建Foo时, 我们用placement new在静态的buf上创建Impl对象. 这样会隐式地结束原本unsigned char的生命周期, 并开始Impl对象的生命周期. placement new返回的指针可以记录着, 以后就可以通过它访问Impl了.\n但这里为了省掉这个额外的Foo::handle成员变量, 我们额外定义一个Foo::get_impl()函数, 帮我们安全地从buf获取Impl对象. 这里需要用到std::launder, 否则从原本的buf指针直接转换得到的Impl*指针并不能用于安全地访问新构建的Impl对象.\n(也就是说, 如果没有std::launder可用, 就需要用一个成员变量记录placement new产生的指针.)\n析构函数中, 需要我们显式地调用Impl上的析构函数.\nABI稳定性 需要注意, 这种做法也部分舍弃了普通PIMPL带来的ABI稳定性的好处, 因为Foo::buf的大小和对齐可能随着Foo::Impl变化.\n一种workaround是把impl_alignment调整得足够大, 并且给impl_size预留足够的空间, 这样Impl增长并不总需要改变buf. 源文件里有static_asset检查, 所以不用担心大小或对齐不够的情况.\n","date":"2024-12-06T00:00:00Z","permalink":"https://kya8.github.io/p/%E4%B8%8D%E7%94%A8%E5%8A%A8%E6%80%81%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0opaque-struct%E5%92%8Cpimpl/","title":"不用动态内存分配如何实现opaque struct和PIMPL?"},{"content":"Signed or unsigned? 在C与C++编程中的一个经典又经常被误解的问题是, 应当使用signed还是unsigned整数类型? 这个问题很早就有标准答案:\nC++核心规范: Arithmetic - ES.100 - ES.107 You should not use the unsigned integer types such as uint32_t, unless there is a valid reason such as representing a bit pattern rather than a number, or you need defined overflow modulo $2^N$. In particular, do not use unsigned types to say a number will never be negative. Instead, use assertions for this.\nSubscripts and sizes should be signed - Bjarne Stroustrup 即: 只要是有算数意义的数字, 除非一些例外情况, 都应当使用signed整型. 算数意义是指, 这个数字如果被用于加减乘除等数学运算或者比较大小, 是有意义的.\n理由和例子 非负逻辑 尤其是, 不要用unsigned整型来表示一个数字逻辑上不能是负数. 这可能是初学者最常见的错误. 这种情况应该在设计时用contract/pre-condition/post-condition来表示, 并在实现代码内用assert来检查.\n例如, 一个函数的参数需要接收一个带有算数意义的整型, 且逻辑上不能为负数. 如果使用Unsigned整型, 调用者传入负数, 那么实际得到的实参也只会被wrap成一个无有效意义的正数, 此时函数内甚至无法判断调用者是不小心传入了负数, 还是真的mean to传入这个被wrap的正数. 并且这个wrap过程是well-defined, 并不能被ubsan之类的工具抓到.\n关于这一条, 最常见的例子就是数组的下标, offset, 以及数组大小. 但在C与C++标准库, 以及其它的OS原生API中, 基本都是用size_t来表示.\nPOSIX规定了ssize_t, 但这个类型仅仅是用来保证能够返回表示错误的一个sentinel值, 它保证能表示的负数只有-1. (当然, 实际上它一般就是size_t的signed版本, 即std::make_signed_t\u0026lt;size_t\u0026gt;). C++标准库中的index与size类型为size_t也可以归为历史遗留问题. 对于自己的代码, 建议使用std::ptrdiff_t或者gsl::index.\n混用signed与unsigned 由于C与C++中关于算术操作的类型转换规则, 在算数操作中混用signed和unsigned整型可能会导致一些不直观的后果, 例如最简单的unsigned(1) \u0026lt; int(-1).\n至于为什么不用unsigned arithmetics, 理由是unsigned整形的算数规则并不直观(如wrap-around), 容易silently导致错误, 难以发现. 并且缺少负数的算术操作也不方便. 如上一点所说, 这类silent的错误经常无法分辨, 对于溢出类错误(严格说, unsigned整型不存在overflow, 超出范围只有well-defined的wrap-around)尽管不会UB, 但也没有任何帮助, 只会让程序带着错误的数据silently继续运行, 引发不可预测的后果. UB至少还可以用一些工具抓到.\n优化 signed整形的overflow是UB, 这一点使得编译器能更好的优化, 例如一些index循环. 关于这一点, 引用Zig的一段介绍:\nCarefully chosen undefined behavior. For example, in Zig both signed and unsigned integers have undefined behavior on overflow, contrasted to only signed integers in C. This facilitates optimizations that are not available in C.\n- ziglang overview\n当然, 在Release build里, UB的后果不可预测, 因此, 最好用一些额外手段确保安全, 例如使用checked arithmetics, 产生溢出错误就直接abort, 或者逻辑上确保不会出现overflow.\n无论如何, 用wrap-around的做法逃避算数溢出都不是一个解决方案!\n其它 对于正常逻辑上非负的数字, 使用signed整形就多出了负数的范围, 可用来作为sentinel值返回错误. 这是十分常见的做法. 至于这种做法本身适不适合(相比于std::optional等其它方式), 属于另一个问题.\n例外情况 这些情况下, 可以允许(或必要)使用unsigned\n非算数意义 bit/byte, 位操作 众所周知, 如果我们只关心访问一串byte, 此时应该使用unsigned char来表示字节. 此外, 对于位操作, unsigned整数也更加方便, 例如用于表示一个bit-field.\n其它 作为一个无算数意义的标记使用. 例如, 一个64位的hash函数一般返回uint64_t. 还有一些格式里的FOURCC标记等magic number. 一个随机发生器的原始输出一般也是unsigned, 作为一串随机的bit使用.\n需要额外的1-bit位宽范围 / 省空间 对于32位, 64位的整形, signed整形正数部分少掉的这一位位宽一般不是问题. 但是, 如果我们要表示0-255范围的数字, 那就需要用uint8_t(不考虑CHAR_BIT \u0026gt; 8的情况), 否则就需要两倍大小. 这种情况下额外的1-bit位宽就matter了. 8bit图像的表示就是常见的例子, 这里的数值显然是具有算数意义的.\nchar / signed char / unsigned char 注意区分这三个不同的基础类型. unsigned char表示raw字节. signed char用于带符号的算数数值. 如上所述, 为了正数位宽也可使用unsigned char. char应仅用于字符, 不应依赖它实际是signed还是unsigned.\n需要wrap-around/modular逻辑 比较少见, 但有时我们事实上确实需要用到wrap-around/modular逻辑\u0026hellip;\n二进制序列化 二进制序列化需要统一的数值二进制表示. 不考虑端序, 对于正整数的表示一般没有异议, 但负整数可能存在差异(尽管也十分少见, 绝大多数平台都是2\u0026rsquo;s complement表示). 因此, 二进制序列化/文件格式中, 对于非负的整数数值一般都是直接使用unsigned表示, 包括定点数的存储. 这样做也可以多出1-bit的正数位宽.\nRust 这些规则大部分并不适用于Rust. Rust中基本的整数类型都适用于算数操作, 可以理解为它们只是具有不同的取值范围, 不允许隐式转换, 并且它们之间的显示转换也是安全的, 除了 as. 对于不安全的转换以及溢出行为, 可以选择使用wrap-around或者panick.\n","date":"2024-08-02T00:00:00Z","permalink":"https://kya8.github.io/p/signed%E4%B8%8Eunsigned%E6%95%B4%E5%9E%8B/","title":"Signed与Unsigned整型"},{"content":"Intro The problem of sampling uniformly in the space of 3D rotations arises commonly in the field of robotics, computer vision, compute graphics etc. The problem is, how do we define \u0026ldquo;uniform\u0026rdquo; in the context of rotations?\nNaive solution A naive method would be sampling the unit rotation axis and the geodesic rotation magnitude separately, both uniformly on $\\mathbb{S}^2$ (i.e. The 2-D sphere of a 3-D ball) and $[0, \\pi]$. This will not give a uniform distribution, as there\u0026rsquo;s a straight forward intuition that is violated by this method. The intuition is that, a rotation of zero rotation angle should have zero probability (or measure) in our desired distribution. At tiny angles, there\u0026rsquo;s not much space for the rotation, beside a little wiggle. As the rotation angle increases, so does the probability of it.\nHowever, this naive solution would yield equal probability for all rotation angles, violating our intuition.\nThe Haar measure Actually, to sample uniformly over a Lie group such as $SO(3)$, the probability density must correspond to the Haar measure, which represents a uniform distribution of the $SO(3)$ group.\nAs we know it, the $SU(2)$ group (or equivalently, all unit quaternions, or the $\\mathbb{S}^3$ hypersphere) forms a proper double cover over $SO(3)$. The $SO(3)$ group space is kind of tricky, since it\u0026rsquo;s not simply connected, with a non-trivia loop of $2\\pi$ rotation. The double cover given by unit quaternions unwraps it into a smooth hypersphere, which is simply connected, and it\u0026rsquo;s volume-preserving.\n(Side note: This intrinsic property of $SO(3)$ gives rise to a interesting phenomenon, where a $2\\pi$ rotation is not equivalent to no rotation, but a $4\\pi$ rotation is. This is demonstrated by the Dirac\u0026rsquo;s string trick)\nThis means we can simply sample uniformly on the space of unit quaternions, which is also the $\\mathbb{S}^3$ hypersphere. It\u0026rsquo;s equivalent to the origin problem.\nUniform sampling on a unit hypersphere The problem now has turned into sampling on the $\\mathbb{S}^3$ hypersphere. A straight forward solution would be sampling from a direction-independent distribution, then normalizing the radius.\nA common approach is to sample each coordinate from independent but identical Gaussian distributions. The probability density would be the product of each Gaussian distribution, which is only determined by the radius $r$. $$ P(\\mathbf{x}) = \\prod_{i}{\\frac{1}{\\sqrt{2\\pi}} \\exp(-\\frac{x_i^2}{2})} \\propto \\exp(-\\frac{r^2}{2}) $$ Afterwards, we normalize this vector, to bring it onto the unit sphere, and interpret it as a unit quaternion, mapping it to a 3D rotation.\nTo see if this distribution aligns with our intuition, we look at it\u0026rsquo;s distribution w.r.t. rotational magnitude:\nLooks like it does.\nParametric sampling on the hypersphere (Hopf fibration). There\u0026rsquo;s a another clever way of uniform sampling on the $\\mathbb{S}^3$ hypersphere, given by the following formula: $$ \\mathbf{q} = (\\sqrt{1-u_1}\\sin(2\\pi u_2), \\sqrt{1-u_1}\\cos(2\\pi u_2), \\sqrt{u_1}\\sin(2\\pi u_3), \\sqrt{u_1}\\cos(2\\pi u_3)) $$ where the parameters $u_1, u_2, u_3 \\in [0, 1]$, are drawn from a uniform distribution.\nLibrary implementations Rotation.random from scipy.\nUniform sampling in SO(n) Eigen::Quaternion::UnitRandom\nSophus::SO3::sampleUniform\nRelated problem: Uniform sampling inside unit ball A related, but not equivalent problem is sampling inside the unit ball.\nReject sampling in a bounding cube should work for lower dimensions. In high dimensions where most volume is concentrated in the reject region, rejection rate is too high for it to be useful.\nAn approach without relying on rejection is to generate a random direction (which we already covered), then normalize the radius parameter.\nFor the n-dimensional unit ball, the direction is given by sampling on its surface, i.e. $\\mathbb{S}^{n-1}$. The radius is drawn from the uniform distribution $U \\in [0, 1]$, then normalized to account for the volume element, that is: $r = U^{1/n}$.\nReferences Sim, Robert, and Gregory Dudek. \u0026ldquo;Learning generative models of scene features.\u0026rdquo; International Journal of Computer Vision 60 (2004): 45-61.\nAlexa, Marc. \u0026ldquo;Super-fibonacci spirals: Fast, low-discrepancy sampling of so (3).\u0026rdquo; Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.\nhttps://mathworld.wolfram.com/HyperspherePointPicking.html\n","date":"2024-07-08T00:00:00Z","permalink":"https://kya8.github.io/p/uniform-sampling-of-so3-rotations/","title":"Uniform sampling of SO(3) rotations"},{"content":"std::signal and signal handlers The standard function std::signal enables registering signal handlers that are invoked when a given signal is delivered, asynchronously. Since the handler can interrupt the execution of the program at potentially any point, actions allowed in the handler are quite limited. In particular, the handler is allowed to access a global (with static storage duration) variable that is volatile std::sig_atomic_t or lock-free std::atomic\u0026lt;...\u0026gt;. This lets us set a flag inside the handler, and correctly check the flag outside the handler. Additionally, a signal handler can re-call std::signal for the same signal that is currently being handled.\nThe POSIX standard specifies additional library functions that are guaranteed to be async-signal-safe, that is, safe to call from signal handlers (See man 7 signal-safety). However on POSIX systems, the sigaction family of functions should be preferred.\nPortable ways to catch signals Suppose we need to catch a signal and inform the program about it, so it can act accordingly. E.g., catching SIGINT (Ctrl-C) to perform graceful cleanup and shutdown. The canonical way of doing this is to have a dedicated thread that responds to a global flag, which shall be set by the signal handler.\nBefore C++20, there\u0026rsquo;s no platform-independent way, besides polling the flag repeatedly:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 static std::atomic\u0026lt;bool\u0026gt; flag{false}; // assuming it\u0026#39;s lock-free extern \u0026#34;C\u0026#34; void signal_handler(int sig) { if (sig == SIGINT) { flag.store(true); } } void sigint_thread_fn(/*...*/) { // demonstration only while(!flag.load()) { std::this_thread::sleep_for(std::chrono::milliseconds(100)); } // precede to perform shutdown actions ... // e.g., signaling the main thread to stop. } \u0026hellip;Because we don\u0026rsquo;t have a signal-safe function to wait on the atomic flag.\nstd::atomic\u0026lt;T\u0026gt;::wait() C++20 introduces wait() and notify() methods on std::atomic\u0026lt;T\u0026gt; and std::atomic_flag. If the atomic type is lock-free (which is always the case for std::atomic_flag), we can safely use wait() and notify() in the waiting thread and the signal handler, to avoid the sleep-and-poll loop above.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 static std::atomic_flag flag{}; // Always lock-free // C++20 guarantees it\u0026#39;s initialized to false extern \u0026#34;C\u0026#34; void signal_handler(int sig) { if (sig == SIGINT) { flag.test_and_set(); flag.notify_all(); } } void sigint_thread_fn(/*...*/) { flag.wait(false); // will block until flag has been changed. // ... } Platform-dependent ways POSIX Incrementing a POSIX semaphore (sem_post) is signal-safe according to the POSIX specification. This can be used for notification in signal handlers. The waiting thread would wait via sem_wait.\nAlternatively there is sigwaitinfo and sigwait, which explicitly wait for pending signals.\nIf you\u0026rsquo;re on Linux, another alternative would be using signalfd and waiting on the file descriptor (e.g. via epoll).\nWindows ","date":"2024-05-20T00:00:00Z","permalink":"https://kya8.github.io/p/portable-signal-handling/","title":"Portable Signal handling"},{"content":"(这只是一个记录贴. 最近又需要在Linux机器上弄一台Windows开发虚拟机, 遂翻出了几年前的记录, 并针对较新的Qemu版本做了一些更新.)\nTL;DR Qemu命令行参数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 qemu-system-x86_64 -accel kvm -machine q35 -name windows \\ -cpu host,hv_relaxed,hv_spinlocks=0x1fff,hv_vapic,hv_vpindex,hv_synic,hv_time,hv_stimer,hv_tlbflush,hv_tlbflush_ext,hv_ipi,hv_stimer_direct,hv_runtime,hv_frequencies,hv_reenlightenment,hv_avic,hv_xmm_input,hv_evmcs \\ -smp sockets=1,cores=8,threads=1 \\ -m 8G \\ -rtc base=localtime \\ -drive if=pflash,format=raw,readonly=on,file=OVMF_CODE.fd -drive if=pflash,format=raw,file=OVMF_VARS.fd \\ -device virtio-balloon \\ -vga none -device virtio-vga \\ # qxl: -device qxl-vga,xres=1920,yres=1080,vgamem_mb=32 -audiodev pipewire,id=snd0 -device ich9-intel-hda -device hda-output,audiodev=snd0 \\ -device qemu-xhci,id=xhci -device usb-tablet \\ -drive file=disk0.qcow2,if=virtio,discard=unmap \\ -nic user,model=virtio-net-pci,guestfwd=tcp::1080-tcp:127.0.0.1:1080 \\ # virtiofs share -object memory-backend-memfd,id=mem,size=8G,share=on -numa node,memdev=mem -chardev socket,id=char0,path=/tmp/vm-share -device vhost-user-fs-pci,chardev=char0,tag=my-share \\ # For installing Windows -drive file=windows.iso,index=2,media=cdrom \\ -drive file=virtio-win.iso,index=3,media=cdrom Virtiofsd:\n1 /usr/libexec/virtiofsd --socket-path=/tmp/virtiofs-share.sock --shared-dir /path/to/shared/dir 关于Qemu命令行 推荐阅读: https://archive.fosdem.org/2018/schedule/event/vai_qemu_jungle/\nQemu的一些选项经常让新手困惑, 主要原因其实就是:\nQemu模拟的每个虚拟设备都由host backend和guest device两部分组成. 两部分一般用一个名字(id)相联系. 诸如-nic, -drive之类的选项只是为了便利提供的shortcut, 能够同时配置两部分.\n例如, -nic user,model=virtio-net-pci的完整写法是--device virtio-net-pci,netdev=n1 --netdev user,id=n1\nQemu的一个system emulator一般会有一些默认模拟的设备, 即使不加任何命令行参数都会被模拟. 例如, x86的system emulator默认会模拟一个vga显卡等.\n参数说明 芯片组和CPU x86-64上一般使用q35机型即可. -cpu host表示使用主机的CPU型号, 并且会开启对应的指令集支持. 后面的一串hv_*是hyper-v enlightments, 适用于Windows客户机.\n用-smp选项可指定CPU的拓扑关系, 这里指定一枚CPU, 8个核心, 每个核心有1个线程.\nUEFI固件 利用OVMF提供的edk2固件, 实现UEFI启动. 一般发行版都会打包OVMF固件, 没有的话可以从网上下载. 固件分为只读和可写两部分, 以pflash形式添加.\n显卡 Qemu给x86客机默认模拟的是一个基本的VGA设备, 足以用于Windows客机显示. 除此之外可选的是virtio-vga和qxl-vga. 前者可选择OpenGL加速(基于API转发, 目前对Windows无效), 后者主要用于给SPICE远程连接.\n它们都是兼容VGA的, 在virtio驱动iso里包含对应的驱动. 这些Windows驱动都是DoD(Display only driver)驱动, 没有Windows上的图形加速功能, 用处不大, 功能上和基本的VGA无异.\n参看: https://www.kraxel.org/blog/2019/09/display-devices-in-qemu/ (很有价值的blog, 来自qemu开发者)\n(如果要求图形性能, 还是需要GPU直通或GPU虚拟化, 目前Qemu中没有虚拟显卡能给Windows客机提供较好的图形加速. 不过, 我们的目的仅是一个Windows开发机, 普通的VGA显示已足够.)\n声音 主机Backend部分上面选择了pipewire. 此外也可以用pulseaudio等. -device ich9-intel-hda -device hda-output,audiodev=snd0添加了两个客机设备, 分别是audio controller和audio codec, 和前面的backend id对应.\nUSB, 输入 一些芯片组(包括q35)具有自带的USB支持, 可用-usb开启. 但这里我们选择了qemu-xhci, qemu实现的一个通用的USB 3.0总线设备.\n鼠标输入采用usb-tablet. tablet设备的用处类似于触摸屏, 即Qemu无需grab input, 鼠标划过Qemu显示窗口时, 就自动输入到客机桌面中.\n键盘方面, Qemu的x86 system emulator会默认模拟, 不需要手动添加.\n存储 直接使用一块virtio-scsi硬盘: -drive file=disk0.qcow2,if=virtio,discard=unmap\nif=virtio在较早版本的Qemu上应该是virtio-blk驱动. 新版本的Qemu里则默认是virtio-scsi总线上的scsi硬盘, 相当于:\n1 2 -drive if=none,id=hd1,format=qcow2,file=disk0.qcow2,discard=unmap -device scsi-hd,drive=hd1 qcow2硬盘镜像可用qemu-img自行创建.\nTRIM virtio-scsi以及virtio-blk存储设备均支持TRIM指令(即scsi标准中的unmap), 可用discard=unmap开启. 通过这种方式, 客机能直接告知主机, 存储中的哪些部分已经不再使用, 可以释放. 在这之前, 常见的老办法是在客机内写入一个全部为0的大文件, 直到把硬盘填满, 再把这个文件删除, 此时硬盘上的空闲空间应该全部是0, 随后将主机上的镜像文件转为稀疏文件.\n对于不同的主机存储backend, 收到来自客机的TRIM指令后的处理方式也不同. 对于qcow2和raw镜像文件, Qemu的处理方式是给文件中被trim的空闲部分punch hole, 使之成为稀疏文件, 从而减少镜像文件的实际硬盘占用. 这一点可用ls -lhs或du disk0.qcow2 ; du --apparent-size disk0.qcow2来验证.\nWindows客机在删除文件时会自动trim. 也可以使用自带的硬盘优化工具给硬盘手动trim, 其中虚拟硬盘会被显示为\u0026quot;Thin provisioned drive\u0026quot;.\n安装盘 安装时, 我们需要以cdrom形式添加windows的安装iso, 以及包含virtio windows驱动的iso. 安装过程中, 需要先加载virtio存储驱动, 才能看到硬盘并继续安装.\n网络 如果在意网络性能, 最好是使用一个由主机上的一个虚拟interface back的tap设备. 简便起见, 这里使用了qemu自带的user-mode networking, 作为主机backend. 客机设备则是virtio网卡, 需要安装对应驱动.\nuser-mode networking自带了端口转发功能, 两个方向均可. 上面的配置是把客机发向虚拟内网中主机(网关)1080端口的tcp包转发到本机的127.0.0.1:1080处.\nvirtiofs文件共享 目前Qemu上性能最好的共享文件方案就是virtiofs, 它是基于共享内存实现, 性能远高于9pfs或者其它基于网络层的方案.\n客机部分: Windows上的virtiofs文件系统驱动是用WinFsp实现, 这个相当于Windows上的FUSE, 需要在客机提前安装好. 此外, 需要安装好virtiofs的客机驱动和服务. 这部分可以直接安装virtio驱动iso中的guest工具包. 安装后在services.msc中找到并开启virtiofs服务即可.\n主机部分: 运行virtiofsd, 指定通讯用socket路径和共享文件路径即可; 在对应的Qemu参数中, 配置好共享内存和socket, 并添加vhost-user-fs-pci设备.\n其它 -rtc base=localtime: 由于Windows默认认为硬件时钟是本地时区. 因此将模拟的硬件时钟设为本地时区. (假设客户机的时区和本机相同) -device virtio-balloon: ballon设备帮助qemu主进程释放客户机空闲的内存. 结果 ","date":"2024-03-12T00:00:00Z","permalink":"https://kya8.github.io/p/qemu-windows-guest-best-practices/","title":"Qemu windows guest best practices"},{"content":"Recursive references Recursive data structures are data types that refers to themselves. Chances are you\u0026rsquo;re already familiar with linked lists:\n1 2 3 4 struct ListNode { int data; ListNode* next; }; A ListNode owns some data, and contains a (non-owning, nullable) reference to the next node.\nWhy does this work? Because C/C++ allows to define a reference to an incomplete type. If we leave out the pointer part of next, the compiler should complain about something like this:\nerror: field \u0026lsquo;next\u0026rsquo; has incomplete type \u0026lsquo;ListNode\u0026rsquo;\nnote: definition of \u0026lsquo;struct ListNode\u0026rsquo; is not complete until the closing brace\n\u0026hellip;, which is self-explanatory: During the definition of a struct, the struct itself is seen as an incomplete type. An incomplete type has unknown size, so the compiler couldn\u0026rsquo;t figure out how much storage it\u0026rsquo;ll use.\nHowever, references/pointers to incomplete types are allowed here, because they have fixed size, in terms of implementations.\nOwnership For simple one-way linked lists, it is possible to replace the raw pointer with std::unique_ptr\u0026lt;ListNode\u0026gt;, so the first node automatically owns the entire list by recursion.\nRecursive variant std::variant is often employed to represent data with runtime-variable type. A recursive variant is a variant type that is able to store itself, which is useful for hierarchical data structures. For example, a property list structure could represent its node using using Node = std::variant\u0026lt;t1, t2, t3, ... , Self\u0026gt;, where Self is some type that contains another (child) Node. An instance of Node is a leaf node if it\u0026rsquo;s not of type Self.\nWe cannot simply write using Node = std::variant\u0026lt;t1, ..., Node\u0026gt;, since recursive using is simply not allowed. Some sort of indirection struct is required here. We could forward declare a struct that contains Node, and use it with the variant. What if:\n1 2 3 4 using Node = std::variant\u0026lt;t1, t2, t3, ... , struct NodeHolder\u0026gt;; struct NodeHolder { Node node; }; Again, this won\u0026rsquo;t work either. To determine sizeof(Node) would be an infinite recursion.\nSimply wrap the forward declared struct inside a smart pointer:\n1 2 3 4 using Node = std::variant\u0026lt;t1, ..., std::unique_ptr\u0026lt;struct NodeHolder\u0026gt;\u0026gt;; struct NodeHolder { Node node; }; This way, the parent node has ownership over the child node (if it has one). The additional price we pay is dynamic memory allocation.\nLet\u0026rsquo;s test this with some examples:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 using VPtr = std::unique_ptr\u0026lt;struct S\u0026gt;; using V = std::variant\u0026lt;int, float, VPtr\u0026gt;; struct S { V v; }; struct Visitor { using std::cout; void operator()(const int\u0026amp; i) const { cout \u0026lt;\u0026lt; \u0026#34;int: \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } void operator()(const float\u0026amp; f) const { cout \u0026lt;\u0026lt; \u0026#34;float: \u0026#34; \u0026lt;\u0026lt; f \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } void operator()(const VPtr\u0026amp; p) const { cout \u0026lt;\u0026lt; \u0026#34;VPtr: \u0026#34;; std::visit(*this, p-\u0026gt;v); // recurse visitation } }; int main() { V v1{1}; V v2{std::unique_ptr\u0026lt;S\u0026gt;{new S{std::move(v1)}}}; // v2 now owns v1 V v3{std::unique_ptr\u0026lt;S\u0026gt;{new S{std::move(v2)}}}; // v3 now owns v2 // make_unique? See: https://wg21.link/p0960 std::visit(Visitor{}, v1); std::visit(Visitor{}, v3); } This should print:\n1 2 int: 1 VPtr: VPtr: int: 1 Inside main(), v1 is constructed, then moved into v2 as a child. v2 is again transferred to v3. Since v1 contains a plain int, the first move is equivalent to a copy. Semantically, v3 owns all the data, and is automatically released when dropped. The Visitor prints data contained in V, and if it has a child node, visit that child node recursively.\nRemoving the wrapper type We had to wrap the Node inside a wrapper type, since forward declaration doesn\u0026rsquo;t make sense for a using alias. We could get around this via inheritance:\n1 struct Node : std::variant\u0026lt;t1, ..., std::unique_ptr\u0026lt;Node\u0026gt;\u0026gt; {}; Use with map V isn\u0026rsquo;t particularly useful, it only serves as a demonstration. In practice, we\u0026rsquo;re more likely to place the variant in some container, e.g.:\n1 2 3 4 5 using Map = std::map\u0026lt;std::string, std::variant\u0026lt;t1, t2, ..., std::unique_ptr\u0026lt;struct MapHolder\u0026gt;\u0026gt;\u0026gt;; struct MapHolder { Map map; }; The intent is clear: Map should be able to store instances of itself as its values. The above approach requires two dynamic-allocated indirections, one of which (the unique_ptr) is redundant.\nWe could go the other way around, by declaring the value type first:\n1 2 3 4 5 6 struct Value : std::variant\u0026lt;int, float, /*... more types*/ std::map\u0026lt;std::string, Value\u0026gt;\u0026gt; {}; void test() { Value r1{42}; Value r2{std::map{ std::pair{std::string(\u0026#34;key\u0026#34;), std::move(r1)} }}; } Or, to make our intent clearer:\n1 2 3 4 5 struct Value; using Map = std::map\u0026lt;std::string, Value\u0026gt;; struct Value : std::variant\u0026lt;int, float, /*... more types*/ Map\u0026gt; {}; //... Application: A heterogeneous data structure We could represent a JSON-like data structure that can hold heterogeneous data recursively, using the tricks demonstrated above.\nThe data representations:\n1 2 3 4 5 6 7 8 9 10 11 12 struct Value; using Map = std::map\u0026lt;std::string, Value\u0026gt;; using Array = std::vector\u0026lt;Value\u0026gt;; struct Value : std::variant\u0026lt;int, std::string, Array, Map\u0026gt; { // Inherit constructors and assignment op, to make things easier. using std::variant\u0026lt;int, std::string, Array, Map\u0026gt;::variant; template\u0026lt;class Ts\u0026gt; auto\u0026amp; operator=(Ts\u0026amp;\u0026amp; rhs) { std::variant\u0026lt;int, std::string, Array, Map\u0026gt;::operator=(std::forward\u0026lt;Ts\u0026gt;(rhs)); // Add more types, e.g. double here. return *this; } }; We could serialize Value into string, recursively:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 void print_value(const Value\u0026amp; val, std::ostream\u0026amp; out) { const auto visitor = [\u0026amp;](const auto\u0026amp; v) { using T = std::decay_t\u0026lt;decltype(v)\u0026gt;; if constexpr (std::is_same_v\u0026lt;T, int\u0026gt;) { out \u0026lt;\u0026lt; v; } else if constexpr (std::is_same_v\u0026lt;T, std::string\u0026gt;) { out \u0026lt;\u0026lt; \u0026#39;\u0026#34;\u0026#39; \u0026lt;\u0026lt; v \u0026lt;\u0026lt; \u0026#39;\u0026#34;\u0026#39;; } else if constexpr (std::is_same_v\u0026lt;T, Array\u0026gt;) { bool first = true; out \u0026lt;\u0026lt; \u0026#39;[\u0026#39;; for (const auto\u0026amp; x : v) { if (!first) { out \u0026lt;\u0026lt; \u0026#34;, \u0026#34;; } first = false; print_value(x, out); } out \u0026lt;\u0026lt; \u0026#39;]\u0026#39;; } else if constexpr (std::is_same_v\u0026lt;T, Map\u0026gt;) { bool first = true; out \u0026lt;\u0026lt; \u0026#39;{\u0026#39;; for (const auto\u0026amp; [key, x] : v) { if (!first) { out \u0026lt;\u0026lt; \u0026#34;, \u0026#34;; } first = false; out \u0026lt;\u0026lt; key \u0026lt;\u0026lt; \u0026#34;: \u0026#34;; print_value(x, out); } out \u0026lt;\u0026lt; \u0026#39;}\u0026#39;; } }; std::visit(visitor, val); } The visitor is a generic lambda that can be applied to all types represented by Value. It recurses into Array or Map types.\nTo put things together:\n1 2 3 4 5 6 7 int main() { Value r2{Map{ std::pair{std::string(\u0026#34;key\u0026#34;), Value{42}} }}; std::get\u0026lt;Map\u0026gt;(r2)[\u0026#34;arr\u0026#34;] = Array{\u0026#34;abc\u0026#34;, 123}; print_value(r2, std::cout); } It prints:\n1 {arr: [\u0026#34;abc\u0026#34;, 123], key: 42} , as expected.\n","date":"2024-02-18T00:00:00Z","permalink":"https://kya8.github.io/p/recursive-stdvariant/","title":"Recursive std::variant"},{"content":"前言 C++20开始, 标准库中提供了ranges模块, 其核心就是各种iterator adaptor, 通过它们的灵活组合, 变换, 能够以简练清晰的代码实现相当复杂的遍历逻辑, 并且没有额外性能开销. 与它们对应的就是Rust的std::iter, 或是Python的itertools.\n这篇文章会通过对几个iterator adaptor / range的简单实现, 浅窥iterator adaptor的背后思想和一些实现细节.\nC++ Iterator和Range C++中的Iterator相当灵活, 但也比较繁琐. 简单来说, 我们把能够用于range-for的对象称为是一个range, 也就是说能从这个对象上调用begin(), end()等函数, 获取一对迭代器, 然后用这组迭代器进行一一遍历. 而具体的迭代逻辑, 就由operator++, operator*等实现. end()获取的iterator, 仅是一个sentinel值, 用于区分迭代是否应当结束.\n这个从range对象取出一对iterator的逻辑, 刚接触时会有点别扭. 我们若是要自己实现一个range(不管是对其它range的一个adaptor还是自己生成), 就需要实现一个range类, 包含遍历所需的所有信息, 并能够生成begin和end两个起止的iterator. 这两个iterator一般也需要一个单独的类, 记录迭代时的状态信息等.\nenumerate 我们从比较简单的enumerate开始. 这个iterator adaptor会在输入的iterator的基础上, 返回一个std::pair的range, 包含每个元素的序号和内容(引用原range的目标).\n这里直接给出代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 namespace details { template \u0026lt;typename T, typename = std::void_t\u0026lt;decltype(std::begin(std::declval\u0026lt;T\u0026amp;\u0026gt;())), decltype(std::end(std::declval\u0026lt;T\u0026amp;\u0026gt;()))\u0026gt;\u0026gt; constexpr auto enumerate(T\u0026amp;\u0026amp; t) { using IterT = decltype(std::begin(std::declval\u0026lt;T\u0026amp;\u0026gt;())); using IterTraits = std::iterator_traits\u0026lt;IterT\u0026gt;; struct EnumerateIterator { typename IterTraits::difference_type index_; IterT it_; auto operator*() const { // This returns a temporary value, not by reference. return std::pair\u0026lt;decltype(index_), decltype(*it_)\u0026gt;{index_, *it_}; } bool operator==(const EnumerateIterator\u0026amp; rhs) const { return it_ == rhs.it_; } bool operator!=(const EnumerateIterator\u0026amp; rhs) const { return it_ != rhs.it_; } auto\u0026amp; operator++() { ++index_; ++it_; return *this; } }; struct EnumerateIterableProxy { T t_; // rvalue t will be moved in. // Cannot use T\u0026amp;\u0026amp; here, since \u0026#34;a temporary bound to a reference parameter in a function call exists until the end of the full expression containing that function call\u0026#34;, // so enumerate(rvalue_here()) won\u0026#39;t work as expected. EnumerateIterator begin() { return {0, std::begin(t_)}; } EnumerateIterator end() { return {-1, std::end(t_)}; } }; return EnumerateIterableProxy{std::forward\u0026lt;T\u0026gt;(t)}; } } // namespace details template \u0026lt;typename T\u0026gt; constexpr auto enumerate(T\u0026amp;\u0026amp; t) { return details::enumerate(std::forward\u0026lt;T\u0026gt;(t)); } 这里的enumerate是用函数的形式实现, 返回了函数内部所定义的一个类EnumerateIterableProxy. 在函数外部, 用户不能创建这个类, 但仍可以正常访问这个类的成员.\n我们把外部的enumerate转发到了details命名空间下的一个内部实现函数, 主要是为了让外部函数的模版参数不带有额外参数. details::enumerate在模版参数上, 通过检查参数类型T是否具有需要的begin和end, 限制了输入T的类型. (这里用了C++17的std::void_t)\nstd::declval\u0026lt;T\u0026amp;\u0026gt;中加了一个左值引用: 因为如果函数接收的是右值, 那么std::declval\u0026lt;T\u0026gt;()会返回一个右值引用, 其本身是一个右值. 而std::begin不允许右值参数. 因此我们强制确保它是左值.\n最终返回的EnumerateIterableProxy对象是直接由输入的T\u0026amp;\u0026amp; t构建, 不难看出, 经过完美转发后, EnumerateIterableProxy中的成员t_要么直接通过move, 将t转移至EnumerateIterableProxy内部的值类型, 要么成为一个对t的左值引用. 前者是接收右值的情况, 后者是接收左值. 没错, 如果是左值我们就引用它, 如果是右值我们就直接把它搬进来, 把所有权交给EnumerateIterableProxy. EnumerateIterableProxy引用或占有t后, 由它产生的iterator就能安全的引用t中的元素.\n具体的enumerate逻辑位于EnumerateIterator之中. EnumerateIterator持有两个成员: 序号和当前的原range的iterator. 递增时, 序号和原iterator一起递增. 比较操作就是比较原iterator. 由于EnumerateIterableProxy给出的end iterator持有原先的end, 因此EnumerateIterator会随着原range一起终止.\nEnumerateIterator的解引用操作是把序号和对相应元素的引用, 装进pair里返回. 注意这里是按值返回, 和常见的iterator的operator*()按引用返回不同. 这里给出cppreference上的一段说明:\nFor an input iterator X that is not a LegacyForwardIterator, std::iterator_traits\u0026lt;X\u0026gt;::reference does not have to be a reference type: dereferencing an input iterator may return a proxy object or std::iterator_traits\u0026lt;X\u0026gt;::value_type itself by value (as in the case of std::istreambuf_iterator). 对于仅满足Input Iterator的iterator, operator*()可以按值返回.\niterator_traits 这里利用了std::iterator_traits, 主要是为了能自动支持普通数组, 例如string literal.\n使用例 1 2 3 for (auto\u0026amp;\u0026amp; [i, c] : enumerate(\u0026#34;Hello!\u0026#34;)) { std::cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; (c? c : \u0026#39;%\u0026#39;) \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // % indicates NUL } 运行结果:\n1 2 3 4 5 6 7 0: H 1: e 2: l 3: l 4: o 5: ! 6: % zip zip的作用是, 输入任意多个range, 并将它们合并遍历, 即每次迭代所有的range. 直到某个主range终止, 或者其中任意一个range终止. 类似于Python的zip, 以及Rust的zip. 不过Rust由于缺少Variadic Generics, 标准库中的zip只能接收2个输入. 如果要多个输入, 需要用宏.\n我们实现的版本中, 会把第一个range作为主range, 以它的终止作为终止. 也就是要求其它Range需要至少和它一样长. 此外, 这次我们改用begin和end对来接收range. 没有什么本质区别.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 template \u0026lt;typename Iter0, typename ...Iters\u0026gt; constexpr auto zip(Iter0 begin0, Iter0 end0, Iters ...Begins) { struct ZipIterator { Iter0 iter0_; // the pivot std::tuple\u0026lt;Iters...\u0026gt; iters_; auto operator*() const { return std::apply([this](auto\u0026amp;\u0026amp; ...iters) { return std::tuple\u0026lt;decltype(*begin0), decltype(*Begins)...\u0026gt;{*iter0_, (*iters)...}; }, iters_); } bool operator==(const ZipIterator\u0026amp; rhs) const { return iter0_ == rhs.iter0_; // only the pivot is compared! // Ideally, all iters should be compared, except when iter0 has reached end. } bool operator!=(const ZipIterator\u0026amp; rhs) const { return iter0_ != rhs.iter0_; } auto\u0026amp; operator++() { ++iter0_; std::apply([](auto\u0026amp;\u0026amp; ...iters) { ((++iters),...); }, iters_); return *this; } // These are made-up. You should probably use something more sensible. using difference_type = typename std::iterator_traits\u0026lt;Iter0\u0026gt;::difference_type; using value_type = std::tuple\u0026lt;decltype(*begin0), decltype(*Begins)...\u0026gt;; using pointer = void; using reference = const value_type\u0026amp;; using iterator_category = std::input_iterator_tag; }; struct ZipProxy { Iter0 begin0_, end0_; std::tuple\u0026lt;Iters...\u0026gt; iters_; ZipIterator begin() { return {begin0_, iters_}; } ZipIterator end() { return {end0_, iters_}; } }; return ZipProxy{begin0, end0, {Begins...}}; } 与前面的enumerate类似, 我们仍然是返回函数内部定义的ZipProxy类. 我们需要储存主range的begin和end, 以及所有其它range的begin.\n为了储存其它所有begin iterator (即Iters ...Begins这个可变参数), 我们直接使用了std::tuple. 这里没必要去自己实现, 因为自己实现相当于重新发明一遍tuple.\n从ZipProxy产生的ZipIterator, 会被赋予主range的iterator, 以及其它range的iterator. ZipIterator的比较操作仅取决于主iterator. 递增就是把每个iterator递增. 而解引用操作, 返回了一个tuple, 装着所有当前元素的引用.\n为了实现递增和解引用, 我们直接对tuple使用std::apply, 把装着iterators的tuple展开成函数参数, 在一个lambda函数中对这些iterator进行遍历操作或展开. 其中递增操作用了一个comma fold.\n使用例 1 2 3 4 5 const std::vector v{2,3,4}; const char* s = \u0026#34;abc\u0026#34;; for (const auto [vv, ss] :zip(v.cbegin(), v.cend(), s)) { std::cout \u0026lt;\u0026lt; vv \u0026lt;\u0026lt; \u0026#34; | \u0026#34; \u0026lt;\u0026lt; ss \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } 运行结果:\n1 2 3 2 | a 3 | b 4 | c NdIndex 即numpy.ndindex. 严格来说它不是iterator adaptor, 而是一个每次生成新元素的range.\n它也是笛卡尔积ranges::views::cartesian_product的一种特殊情况, 但实现本质上和cartesian_product没有区别.\n这次我们使用一个类来表示NdIndex. 当然, 用函数产生range也是完全可行的. 这里仅是为了演示.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 template \u0026lt;std::size_t Dim\u0026gt; class NdIndex { private: std::array\u0026lt;std::size_t, Dim\u0026gt; sizes_; public: static constexpr auto ndim = Dim; template \u0026lt;typename ...Ts\u0026gt; constexpr NdIndex(Ts ...Args) noexcept : sizes_{std::size_t(Args)...} {} class Iter { friend class NdIndex; private: std::array\u0026lt;std::size_t, Dim\u0026gt; idx_{}; std::array\u0026lt;std::size_t, Dim\u0026gt; sizes_; // helper for loop unrolling template \u0026lt;std::size_t ...Is\u0026gt; constexpr void increment(std::index_sequence\u0026lt;Is...\u0026gt;) noexcept { ([this] { constexpr auto i = Dim - 1 - Is; if constexpr (i == 0) { ++idx_[0]; return true; } else { if (++idx_[i] \u0026lt; sizes_[i]) return false; idx_[i] = 0; return true; } }() \u0026amp;\u0026amp; ...); // short-circuit fold } public: constexpr auto\u0026amp; operator*() const noexcept { return idx_; } constexpr auto\u0026amp; operator++() noexcept { increment(std::make_index_sequence\u0026lt;Dim\u0026gt;{}); return *this; } constexpr bool operator==(const Iter\u0026amp; rhs) const noexcept { return idx_ == rhs.idx_; // sizes? } constexpr bool operator!=(const Iter\u0026amp; rhs) const noexcept { return !(*this == rhs); } public: // traits using difference_type = std::make_signed_t\u0026lt;std::size_t\u0026gt;; using value_type = decltype(idx_); using pointer = void; using reference = const value_type\u0026amp;; using iterator_category = std::input_iterator_tag; }; constexpr auto begin() const noexcept { Iter it; it.sizes_ = sizes_; return it; } constexpr auto end() const noexcept { Iter it; it.idx_[0] = sizes_[0]; it.sizes_ = sizes_; return it; } }; // CTAD guide template\u0026lt;typename ...Ts\u0026gt; NdIndex(Ts ...Args) -\u0026gt; NdIndex\u0026lt;sizeof...(Ts)\u0026gt;; NdIndex的唯一模板参数是它的维度个数Dim. 使用者构建NdIndex对象时, 参数为各个维度上的长度. 通过代码末尾处的一个CTAD提示, 我们告诉编译器, 构建函数的参数个数, 就是模板参数Dim. 这里的CTAD guide是必须的.\n显然, NdIndex类需要保存每个维度上的最大长度. 而NdIndex给出的iterator, 即它的子类NdIndex::Iter, 则需要当前的每个维度的下标, 以及最大长度. 而iterator的比较操作, 就是逐个比较它们保存的所有下标. 此外, end iterator是通过最高维度的下标达到长度值来表示, 到此就应终止迭代.\n为了方便, 我们直接用std::array, 自动提供赋值, 比较等操作. 同时作为operator*()的返回值, 它也是一个tuple-like的类, 能够被structured binding展开.\n递增 NdIndex的主要逻辑实现在于它的递增函数. 为了编译期展开循环, 我们把operator++()用std::index_sequence做了一次转接, 以便在increment函数中按每个维度展开.\nincrement函数的每次执行, 是把一个IIFE表达式 (立即执行的lambda函数, 这里的目的是为了把多行代码就地变成一个返回true或false的expression) 按照编译期确定的0, 1, ..., Dim-1几个维度展开, 展开后用\u0026amp;\u0026amp;算符实现短路执行: 即当某个维度的IIFE返回false后, 剩下维度的操作就不会被执行.\n注意IIFE按维度执行的顺序是从低维开始. 这个IIFE表达式的意义就比较明晰了:\n如果是最高的维度(这是一个编译期判断), 就直接把这个维度加1, 加到最大后迭代就会停止. 返回true或false无所谓, 因为这是逻辑和的最后一个表达式. 如果是其它维度, 那么 如果加1后还未达到长度值, 就直接返回false, 结束本次increment. 如果加1后达到了长度值, 就进位: 把这一维度设为0, 然后返回true, 继续更高维度. Tip: 用\u0026amp;\u0026amp;算符的fold expression, 实现可在运行时跳出的编译期循环! 有点绕)\n改进 这里的NdIndex的下标类型是固定的size_t, 不难把它改成以整数类型为模板参数的类模板. NdIndex存在一个potential的bug, 即处理各维度的长度之一(除了最高维度)是0的情况. 当前的行为相当于直接跳过了这个维度, 它一直是0. 但我认为正确的行为应当是使整个range为空. 如果要实现这个行为, 只需要和end比较时, 比较每个维度是否达到了最大值. 总结 上面的三个实现都是出于PoC展示的目的, 并不算严密, 如果要作为一个正式的库发布, 还有不少需要修改的地方, 但可以作为iterator adaptor的概念展示, 读者看完后, 应该不难在C++20之前的版本自己实现其它的adaptor.\nadaptor组合 组合起来用:\n1 2 3 4 5 6 7 #include \u0026lt;fmt/ranges.h\u0026gt; constexpr auto nd1 = NdIndex{2,3}; constexpr auto nd2 = NdIndex{3,2}; for (const auto\u0026amp; a : enumerate(zip(nd1.begin(), nd1.end(), nd2.begin()))) { fmt::println(\u0026#34;{}\u0026#34;, a); } 由于我们的zip函数是接收begin/end, 因此只能把需要被zip的range单独声明在前.\n运行结果:\n1 2 3 4 5 6 (0, ([0, 0], [0, 0])) (1, ([0, 1], [0, 1])) (2, ([0, 2], [1, 0])) (3, ([1, 0], [1, 1])) (4, ([1, 1], [2, 0])) (5, ([1, 2], [2, 1])) ","date":"2024-01-29T00:00:00Z","permalink":"https://kya8.github.io/p/c-%E5%AE%9E%E7%8E%B0%E7%B3%BB%E5%88%97-iterator-adaptor/","title":"C++实现系列: Iterator adaptor"},{"content":"背景 环形缓存(ring buffer)是一种简单高效的数据结构, 想必不需要过多介绍. 这篇文章主要是以实现一个环形缓存容器类为例, 讲述实现C++容器类过程中的一些注意事项和最佳实践.\n已有的环形缓存实现有boost::circular_buffer, 提供与STL容器兼容的API.\n实现要求及细节考虑 首先, 环形缓存的自身基本功能. 尽量提供与STL容器相同或相似的API. 支持用户自定义的allocator. 默认使用std::allocator. 如果是stateless的allocator, 不占用额外空间. \u0026hellip; 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 template \u0026lt;typename T, typename Allocator = std::allocator\u0026lt;T\u0026gt;\u0026gt; class RingBuffer { private: using alloc_traits = std::allocator_traits\u0026lt;Allocator\u0026gt;; public: using size_type = typename alloc_traits::size_type; using difference_type = typename alloc_traits::difference_type; using value_type = T; using reference = value_type\u0026amp;; using const_reference = const value_type\u0026amp;; using pointer = typename alloc_traits::pointer; using const_pointer = typename alloc_traits::const_pointer; //iterator = ...; using allocator_type = Allocator; RingBuffer(size_type max, const allocator_type\u0026amp; alloc = allocator_type{}) : alloc_and_data_{alloc, {}}, first_(0), count_(0), max_(max) { alloc_and_data_.second() = alloc_traits::allocate(alloc_(), max); } ~RingBuffer() noexcept { clear(); alloc_traits::deallocate(alloc_(), data_(), max_); } RingBuffer(RingBuffer\u0026amp;\u0026amp; rhs) noexcept : alloc_and_data_{std::move(rhs.alloc_and_data_)}, // ensure moving the allocator. The pointer is copied. first_{rhs.first_}, count_{rhs.count_}, max_{rhs.max_} { rhs.alloc_and_data_.second() = nullptr; rhs.count_ = 0; rhs.max_ = 0; rhs.first_ = 0; // rhs shouldn\u0026#39;t be used anymore } RingBuffer\u0026amp; operator=(RingBuffer\u0026amp;\u0026amp; rhs) noexcept { clear(); alloc_traits::deallocate(alloc_(), data_(), max_); alloc_and_data_ = std::move(rhs.alloc_and_data_); // ensure moving the allocator first_ = rhs.first_; count_ = rhs.count_; max_ = rhs.max_; rhs.alloc_and_data_.second() = nullptr; rhs.count_ = 0; rhs.max_ = 0; rhs.first_ = 0; // rhs shouldn\u0026#39;t be used anymore return *this; } private: template\u0026lt;class V\u0026gt; bool push_impl(V\u0026amp;\u0026amp; value) { if (count_ == max_) return false; alloc_traits::construct(alloc_(), data_() + (first_+count_)%max_, std::forward\u0026lt;V\u0026gt;(value)); ++count_; return true; } template\u0026lt;class V\u0026gt; void push_overwrite_impl(V\u0026amp;\u0026amp; value) { if (count_ == max_) pop(); alloc_traits::construct(alloc_(), data_() + (first_+count_)%max_, std::forward\u0026lt;V\u0026gt;(value)); ++count_; } public: bool push(const T\u0026amp; value) { return push_impl(value); } bool push(T\u0026amp;\u0026amp; value) { return push_impl(std::move(value)); } void push_overwrite(const T\u0026amp; value) { return push_overwrite_impl(value); } void push_overwrite(T\u0026amp;\u0026amp; value) { return push_overwrite_impl(std::move(value)); } template \u0026lt;typename ...Args\u0026gt; auto\u0026amp; emplace(Args\u0026amp;\u0026amp; ...args) { if (count_ == max_) pop(); const auto ptr = data_() + (first_+count_) % max_; alloc_traits::construct(alloc_(), ptr, std::forward\u0026lt;Args\u0026gt;(args)...); ++count_; return *ptr; } void pop() noexcept { // UB if empty alloc_traits::destroy(alloc_(), data_()+first_); first_ = (first_+1) % max_; --count_; } void pop_back() noexcept { alloc_traits::destroy(alloc_(), data_() + (first_+count_-1) % max_); --count_; } const auto\u0026amp; operator[](size_type i) const noexcept { return data_()[(first_+i) % max_]; } auto\u0026amp; operator[](size_type i) noexcept { return data_()[(first_+i) % max_]; } auto\u0026amp; at(size_type i) { if (i \u0026gt;= count_) throw std::out_of_range(\u0026#34;RingBuffer subscription out of range\u0026#34;); return (*this)[i]; } auto\u0026amp; at(size_type i) const { if (i \u0026gt;= count_) throw std::out_of_range(\u0026#34;RingBuffer subscription out of range\u0026#34;); return (*this)[i]; } auto\u0026amp; front() const noexcept { return (*this)[0]; } auto\u0026amp; front() noexcept { return (*this)[0]; } auto\u0026amp; back() const noexcept { return (*this)[count_ - 1]; } auto\u0026amp; back() noexcept { return (*this)[count_ - 1]; } bool empty() const noexcept { return count_ == 0; } size_type size() const noexcept { return count_; } size_type capacity() const noexcept { return max_; } void clear() noexcept { for (auto i=first_; i\u0026lt;first_ + count_; ++i) { alloc_traits::destroy(alloc_(), \u0026amp;data_()[i % max_]); --count_; } } private: CompressPair\u0026lt;allocator_type, T*\u0026gt; alloc_and_data_; auto\u0026amp; alloc_() noexcept { return alloc_and_data_.first(); } auto data_() const noexcept { return alloc_and_data_.second(); } size_type first_; size_type count_; size_type max_; }; RingBuffer的最大容量必须在构建时指定. 并且, 所有的动态内存分配也在构建时完成. 此外用户也可以指定自定义的Allocator.\n空基类优化 (Empty Base Optimization) 众所周知, C++中, 一个空的struct一般情况下也要占用至少1字节的空间, 否则无法将它与前后的对象地址区分开 (不过, 对于C++20, 也可以直接使用[[no_unique_address]], 省去空基类优化的技巧). 但是, 对于某个对象内的基类对象, 如果基类为空, C++编译器可以选择使用空基类优化, 即, 去除基类对象的内存表示.\n这个技巧在编译器STL实现的代码中经常可以看到, 一般是为了将容器的allocator和其它成员共同表示, 省去allocator为空时的额外空间占用, 因为大部分情况下, 我们会使用默认allocator (即std::allocator), 或者仅依赖某些全局变量的allocator, 而这些allocator都是无状态的, 没有成员变量.\n上面的实现中为了利用空基类优化, 使用了CompressPair\u0026lt;T1, T2\u0026gt;. 它的实现方法, 是通过类模版的偏特化, 分别处理T1为空和T2为空的情形. 如果T2为空, 那么就以T2为基类. 否则默认以T1为基类. 如此便实现了对空类的\u0026quot;压缩\u0026quot;. 我写了一个简单的实现:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 template \u0026lt;typename T1, typename T2, typename = void\u0026gt; class CompressPair : protected T1 { T2 t2_; public: template\u0026lt;typename U1 = T1, typename U2 = T2\u0026gt; constexpr CompressPair(U1\u0026amp;\u0026amp; x, U2\u0026amp;\u0026amp; y) : T1(std::forward\u0026lt;U1\u0026gt;(x)), t2_(std::forward\u0026lt;U2\u0026gt;(y)) {} constexpr T1\u0026amp; first() noexcept { return *this; } constexpr const T1\u0026amp; first() const noexcept { return *this; } constexpr auto\u0026amp; second() noexcept { return t2_; } constexpr auto\u0026amp; second() const noexcept { return t2_; } }; template \u0026lt;typename T1, typename T2\u0026gt; class CompressPair\u0026lt;T1, T2, std::enable_if_t\u0026lt;std::is_empty_v\u0026lt;T2\u0026gt;\u0026gt;\u0026gt; : protected T2 { T1 t1_; public: template\u0026lt;typename U1 = T1, typename U2 = T2\u0026gt; constexpr CompressPair(U1\u0026amp;\u0026amp; x, U2\u0026amp;\u0026amp; y) : T2(std::forward\u0026lt;U2\u0026gt;(y)), t1_(std::forward\u0026lt;U1\u0026gt;(x)) {} constexpr auto\u0026amp; first() noexcept { return t1_; } constexpr auto\u0026amp; first() const noexcept { return t1_; } constexpr T2\u0026amp; second() noexcept { return *this; } constexpr const T2\u0026amp; second() const noexcept { return *this; } }; 实例化CompressPair时, 会自动匹配合适的类模版. 此后可通过first()和second()访问储存的两个对象. 和普通的std::pair不同, 这里的first()和second()只能写成成员函数, 返回相应的引用.\n在RingBuffer中, CompressPair用于存储allocator和data指针.\nallocator的使用 可以看到, RingBuffer中, 我们总是通过allocator_traits去调用实际的allocator, 而不是直接调用allocator的成员. 因为allocator_traits能够基于用户提供的allocator类, 自动提供默认实现. 否则, 用户提供的allocator需要实现所有要求的成员函数等, 即使我们只需要自定义内存分配/释放的操作.\n事实上, STL中需要动态分配内存的容器都是AllocatorAwareContainer, 规定必须使用allocator_traits.\n此外, C++17开始, std::allocator的allocate, construct成员函数已经是deprecated.\n内存分配与对象构建 众所周知, 一般情况下C++中的对象并不是简单的一串字节, 不能假装某处已分配的内存上有一个对象, 然后去访问它 (隐式构建的对象是例外). 构建对象和分配内存是分开的两种操作, 对于新手来说, 在编写容器类的实现时很容易体会到这一点. 而一些STL容器的实现中, 将两者解耦是必须的, 例如std::vector.\n上面的实现中, RingBuffer仅在构建时一次性分配所需内存. 对于默认的std::allocator, 其行为是用operator new, 分配所需长度的内存. 此时RingBuffer中没有任何对象. 之后, 添加对象时, 我们转发参数给T的构建函数, 在合适的地点就地构建新对象 (一般是使用placement new). 如果需要销毁某个对象, 我们通过allocator_traits执行析构, 结束对象的生命周期.\n在整个过程中, 内存分配和释放仅在RingBuffer构建和析构时发生. 此外, 操作RingBuffer也不会移动其中的对象.\nMove操作 显而易见, RingBuffer是一个直接管理非RAII资源的类 (因为我们把数据用裸指针表示). 根据0/3/5规则, 我们应当给它定义析构函数, 以正确释放资源. 此外, 拷贝操作理应禁止, 或者实现深拷贝. Move操作则是最好能提供.\n这里我们只给RingBuffer实现了Move. 注意Move的手动定义会删除编译器隐式定义的Copy操作, 因此RingBuffer无法被Copy.\n在Move操作中, 我们把右端的CompressPair成员直接Move过来. 这里如果allocator有自己的Move操作, 也会被利用. 其它成员直接拷贝即可. 右端被Move后, 我们需要将它置为空值, 至少得避免它析构时出现double-free之类的错误.\n可以看出, 在这个实现中, 被Move后的RingBuffer是无法再被使用的, 最大容量是0.\n左值与右值引用的重载 push_impl这个helper函数是为了给push使用, 减少代码重复. 众所周知, std::vector等容器的push函数有两个重载, 分别接收左值和右值. 他们的逻辑是一样的, 只是一个转发左值, 一个转发右值. 为了避免这类导致重复的情况, 我们定义一个接收forwarding reference的push_impl, 将两个重载统一转发给它. push_impl内部实现了push的真正逻辑, 且将参数完美转发. 由于push_impl仅会内部使用, 不用考虑类型不对的情况.\n这是一种减少左值/右值重载代码重复的常见方法. 对于较长, 逻辑复杂的函数更有用.\n未完成的部分 Copy操作. 由于我们定义了Move操作, 默认的Copy操作会被删除. Copy的实现只需把成员进行拷贝, 其中对data_部分特殊处理(深拷贝)即可. 当然, 能Copy的前提是, allocator是可Copy的. 对于allocator的Copy, 我们可以直接利用std::allocator_traits\u0026lt;Alloc\u0026gt;::select_on_container_copy_construction. 更改最大容量, 以及按需分配内存. 更改最大容量相对容易实现一些, Move后不能扩容的问题也能一并解决. 但按需分配内存可能会引起性能问题 (在容器被填满之前). Iterator. 这里没法偷懒用T*作为iterator类型, 因为这不是一个连续容器. 因此, 我们的iterator需要记录一些额外信息, 才能正确地从头到尾遍历. 其它STL容器的Requirement. 简洁起见, 这里并没有实现STL容器的所有Requirement, 有一些函数的signature也并不一致. ","date":"2023-11-16T00:00:00Z","permalink":"https://kya8.github.io/p/c-%E5%AE%9E%E7%8E%B0%E7%B3%BB%E5%88%97-%E7%8E%AF%E5%BD%A2%E7%BC%93%E5%AD%98/","title":"C++实现系列: 环形缓存"},{"content":"A compile time loop is a loop that is guaranteed to be expanded at compile time. In contrast, a regular runtime loop typically keeps track of a loop condition at runtime, and checks the condition at every iteration to determine whether to exit the loop.\nAn optimizing compiler is often able to expand some runtime loops in-place, but not always. We\u0026rsquo;ll introduce several ways of composing compile-time loops, using template metaprogramming.\nGeneric formulation Here\u0026rsquo;s the problem: Given a compile time integer sequence of [0, \u0026hellip;, N), apply a function (template) over all N integers. The integers should be available to the function as compile time constants.\nTemplate recursion A common practice is to recurse through all the indices one by one. A non-generic example would be:\n1 2 3 4 5 6 7 8 9 template\u0026lt;unsigned N\u0026gt; constexpr void for_something() { if constexpr (N \u0026gt;= 1) { for_something\u0026lt;N-1\u0026gt;(); // do something with N-1 std::cout \u0026lt;\u0026lt; N-1 \u0026lt;\u0026lt; std::endl; } } This function will loop from 0 to N-1. The if constexpr can be replaced with a template specialization for N=0.\nThe magic constexpr index To make this generic, we could use a template template parameter for a callable, or the way I prefer: a class template parameter which has templated operator(), e.g. a generic lambda.\n1 2 3 4 5 6 7 8 template\u0026lt;unsigned N, typename F\u0026gt; constexpr void for_something(F\u0026amp;\u0026amp; f) { if constexpr (N \u0026gt;= 1) { for_something\u0026lt;N-1\u0026gt;(std::forward\u0026lt;F\u0026gt;(f)); // may be you shouldn\u0026#39;t forward std::forward\u0026lt;F\u0026gt;(f)(std::integral_constant\u0026lt;decltype(N), N-1\u0026gt;{}); } } Use it with a generic lambda:\n1 2 3 4 5 6 7 8 9 for_something\u0026lt;3\u0026gt;([](auto i){ std::cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; std::endl; // the i.value is constexpr! // i even has implicit conversion to its value! if constexpr (i.value == 9999) { static_assert(false, \u0026#34;this should\u0026#39;ve been removed at compile time\u0026#34;); // some dependent false value may be required to make this compile. } }); i can be used as a compile-time integer. The trick here is to pass the compile time index as an std::integral_constant tag value, whose type (which encodes the integer) is then received by the generic lambda. Inside the lambda, i.value is a static, constexpr member of the deduced type decltype(i). Combined with the conversion operator of std::integral_constant which converts to its tag value, i can be used as a compile-time constant.\nstd::interger_sequence With the help of std::make_integer_sequence, we could easily generate a parameter pack of integer sequence, and recurse over the pack. The idea is basically the same, you just extract the first element in the pack, and recurse the rest.\nDrawbacks Template recursion can generate huge amount of instantiations of the same function/class template at compile time, so they are not optimal for compile time performance.\nAs for runtime performance, as long as everything is properly inlined without jumping through all the indirections and recursions, it should be the same as unrolling the loop manually.\nPack expansion and fold expressions Pack expansion hack A common workaround before C++17\u0026rsquo;s fold expressions is to expand the pack into an array initializer:\n1 2 3 4 5 6 template\u0026lt;std::size_t ...Is\u0026gt; constexpr void for_impl(std::index_sequence\u0026lt;Is...\u0026gt;) { bool _arr[] { (some_expression(Is), 0)... }; (void)_arr; } Note: Here, the order of evaluation inside the braces is guaranteed, unlike function arguments.\nFold expressions Fold expressions provide a much nicer way of doing pack iteration and (when combined with std::integer_sequence) compile time loop. Here\u0026rsquo;s a class template which applies a generic function over an integer sequence, expanded at compile time:\n1 2 3 4 5 6 7 8 9 10 11 12 13 template\u0026lt;typename\u0026gt; struct ForInts; template\u0026lt;typename IntT, IntT ...Is\u0026gt; struct ForInts\u0026lt;std::integer_sequence\u0026lt;IntT, Is...\u0026gt;\u0026gt; { template\u0026lt;typename F\u0026gt; static constexpr void apply(F\u0026amp;\u0026amp; f) { (void(f(std::integral_constant\u0026lt;IntT, Is\u0026gt;{})), ...); } }; template\u0026lt;auto N\u0026gt; using ForSeq = ForInts\u0026lt;std::make_integer_sequence\u0026lt;decltype(N), N\u0026gt;\u0026gt;; The ForSeq alias template generates an integer sequence as the template parameter for ForInts. The ForInts class template\u0026rsquo;s apply() method applies a given function object over the indices, by comma-folding over the function expression. It employs the same std::integral_constant trick. The void cast is there to deal with overloaded operator,.\nExample usage:\n1 2 3 4 5 std::ostringstream ss; ForSeq\u0026lt;10\u0026gt;::apply([\u0026amp;ss](auto i) { if constexpr (i.value == 0) ss \u0026lt;\u0026lt; \u0026#34;Start!\\n\u0026#34;; ss \u0026lt;\u0026lt; \u0026#34;loop: \u0026#34; \u0026lt;\u0026lt; i.value \u0026lt;\u0026lt; \u0026#39; \u0026#39;; }); This is a much more natural way of implementing and writing compile-time loops.\nUsing std::make_integer_sequence often involves an indirection to a separate impl function or class, which catches the actual integer list. With explicit lambda template in C++20, we could replace the impl function with an inner lambda:\n1 2 3 4 5 6 template\u0026lt;std::size_t N\u0026gt; constexpr void do_something() { []\u0026lt;template std::size_t ...Is\u0026gt;(std::index_sequence\u0026lt;Is...\u0026gt;) { // fold over Is... }(std::make_index_sequence\u0026lt;N\u0026gt;{}); // IIFE } Runtime break from the loop (short-circuiting) What if we want to break half-way from the compile time loop, depending on some runtime condition? It\u0026rsquo;s trivial to achieve with logical folds, since the \u0026amp;\u0026amp; and || operators in C++ has short-circuiting behavior.\nA partial demo:\n1 2 3 4 5 6 7 8 9 template \u0026lt;std::size_t ...Is\u0026gt; constexpr void fn(std::index_sequence\u0026lt;Is...\u0026gt;) { ([]() -\u0026gt; bool { // do something, return true or false // return true if the loop should be continued. // return false if not. }() \u0026amp;\u0026amp; ...); } The above fn() function will evaluate all folded expressions (here, the expression is an IIFE returning either true or false). If at some point the IIFE returns false, all remaining expressions will be skipped.\nSidenote: Implementation of std::make_integer_sequence Many compile-time loop patterns ultimately boils down to std::make_integer_sequence (or equivalent).\nA naive implementation is one-by-one template recursion. Something smarter would be $\\log_2(N)$ recursion, which obviously works by dividing by half every iteration.\nSince std::make_integer_sequence is ubiquitous in template metaprogramming, some compilers implement it with magic intrinsics.\nMSVC and Clang: __make_integer_seq GCC: __integer_pack ","date":"2023-10-09T00:00:00Z","permalink":"https://kya8.github.io/p/compile-time-loops-in-c-/","title":"Compile time loops in C++"},{"content":"Class invariant A class invariant is a condition that always holds true for any object of the class, throughout its lifetime. Typical class invariants include consistency of some internal state, or that a resource-owning class always acquires and manages some resource.\nProper designing and maintaining of class invariants provides useful guarantees for users (and implementers) that lowers our mental burdens.\nEnforcing class invariant at construction The canonical way is to throw in the constructor, if it fails to establish the required invariants. Alternatively we could force the use of a factory constructor, which returns std::optional\u0026lt;T\u0026gt; or similar.\nDefault-constructed, zombie object Sometimes, we\u0026rsquo;re left with an valid object that fails to meet some condition, e.g. a resource owning class object that hasn\u0026rsquo;t acquired any resources. Such zombie objects are rather common in C++ codebases. For example, if a class invariant requires some argument to construct, a default constructor of the class, if defined, will create a zombie object.\nIn many situations, we\u0026rsquo;re forced to make our class default-constructible (e.g. resizing std::vector)\nA zombie (or null, nil) object is not broken, it just introduces an additional null state, which adds some responsibility/contract of checking the object state on the user (and sometimes on the implementer).\nMove compromises class invariant For a resource owning class, according to the Rule of 0-3-5, we could define custom move constructor and assignment operator for it, which shall transfer resource ownership. However, this requires compromising the class invariant that it always holds a resource, since the moved-from object must have been emptied, and marked as null. A zombie object is leaked by move! This is a price we pay for non-destructive move in C++.\nStill, such weak invariant is better than no invariant at all. We could further weaken the invariant by defining public, non-throwing (default) constructors that create zombie objects.\nIf only move produces zombie objects, we just tell the user not to use moved-from objects of our class, which is not a big deal, and on our side we only need to do additional checking when releasing the resource (to prevent potential double-free, etc.).\nNon-destructive move In C++, moving from an object has nothing to do with its lifetime. It\u0026rsquo;s just a plain function invoked on the rvalue-referenced rhs object, nothing special.\nAlthough the move function can do basically anything, in practice we want it to transfer owned resources, which leaves the moved-from object emptied. And when the object gets out of scope, its destructor gets called, which checks for null and finds it is already emptied.\nThis operation might leave the moved-from object in a null state, but does not terminate its lifetime, thus compromising class invariants. The root of all evil!\nSome languages, e.g. Rust has destructive moves. In Rust, a moved from object is no longer valid, and you get a compile-time error if trying to access them afterwards. This way, moving won\u0026rsquo;t affect class invariants, since it terminates the object\u0026rsquo;s lifetime.\nThe implementation of move semantics in Rust is not much different (it could simply be a memcpy). The magic is language support such that moved-from objects are no longer valid, not the move itself. Also the destructor of the moved-from object will NOT be called, since it is indeed moved, so the responsibility of freeing is transferred away. Compare to C++, a moved-from variable is still there, and can be used as normal, so its destructor still needs to be called when its lifetime actually ends (which means the destructor should check for null).\nIn all, moved-from objects in C++ are (usually meant to be) null objects, while in Rust, moved-from objects are \u0026hellip;., absence of objects!\nSum-types for null We\u0026rsquo;ve talked about zombie/null objects, which embed a special internal state of null (or not).\nIf the class invariant that the object cannot be null always holds, we should lift the null state indication out of the object: If the class invariant fails to establish, then there shouldn\u0026rsquo;t be an object at all!\nIt\u0026rsquo;s basically going from zombie/null object vs. non-null object, to invariant-holding object vs. the absence of object. The latter can be cleanly represented by sum types, such as Optional, Result in Rust, and std::optional, std::expected in C++.\n","date":"2023-09-29T00:00:00Z","permalink":"https://kya8.github.io/p/non-destructive-move-null-object-and-class-invariants/","title":"Non-destructive move, null object and class invariants"},{"content":"Runtime polymorphism in C++ The canonical way of doing runtime polymorphism in C++ has always been virtual functions and inheritance. Compared to alternative solutions found in other languages, such as:\nInterface in Go Trait object in Rust , the virtual function plus inheritance approach is often considered inferior, for the following reasons:\nIntrusive design: All implementers of an interface must inherit from it. The implementation object also has to make room for the vtable! Mandates reference semantics: You can only use the interface polymorphically through pointers or references. A factory function has to return std::unique_ptr\u0026lt;InterfaceType\u0026gt;, which is messy. (To be fair, interface objects also require dynamic allocation internally) Performance cost: They are often found to be slower than alternatives. polymorphic object A polymorphic object type defines a set of methods. Such object can then store another object of abitary type, that implements the defined set of methods.\nPeople have been writing such implementations for years, such as Poly, dyno, proxy.\nbenefits Allows value-semantics, and copying. Although polymorphic objects still require dynamic allocation in the general case, the user does not need to care about it. Copying is possible, by storing function pointers of copying operations. Virtual inheritance on the other hand, does not play nicely with copy constructors! Allows Small buffer optimization. Since they\u0026rsquo;re custom objects, SBO is possible, compared to std::unique_ptr\u0026lt;InterfaceType\u0026gt;. Allows duck typing. Although this isn\u0026rsquo;t always desired. Type erasure Actually, we already have a limited version of polymorphic object in C++: std::function. It only knows about the operator(), but the idea is similar: Use type-erasure.\nFor polymorphic objects, we need to keep the function pointers somewhere, but for potentially multiple member methods.\nTo be continued\u0026hellip;\n","date":"2023-07-11T00:00:00Z","permalink":"https://kya8.github.io/p/type-erasure-and-polymorphic-interface-objects/","title":"Type erasure and polymorphic interface objects"},{"content":"Type erasure Type erasure is a generic concept in progamming, where different types can be hidden behind a single, generic interface. You probably already did type erasure in C: passing void* pointer around and casting them! This is a simple case of type erasure, which is not type safe. A tagged union also counts, although it only provides erasure for a pre-defined set of types.\nstd::function std::function\u0026lt;R(Args...)\u0026gt; is a type-erased polymorphic function object that can wrap all kinds of callables with the specified argument types Args... and a return type that is convertible to R. It stores the provided callable (with ownership) by (forwarding) copy/move. Dynamic allocation is required in the general case, however implementations may use SBO (Small Buffer optimization).\nIt\u0026rsquo;s suitable for use at API boundaries, e.g. when providing a callback, with owning/by-value semantics.\nImplementation The actual type erasure happens inside the constructor. Besides storing the callable type-erased (either by dynamic allocation or SBO), std::function needs to record information about how to do operator() later. Since std::function is copyable, it also needs to remember how to copy the callable!\nThere\u0026rsquo;s even more: If SBO is in effect, to move an std::function would require invoking the callable\u0026rsquo;s move constructor. Otherwise we just move the pointer.\nAll of these has to be done inside the constructor of std::function since the type information of the callable is only available there. Here\u0026rsquo;s a limited implementation I wrote. It has no SBO, and doesn\u0026rsquo;t support all kinds of callables (e.g. member function pointers):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 struct Ptrs { void(*deleter_ptr)(void*); void*(*copy_ptr)(void*); }; template\u0026lt;class T\u0026gt; struct TypePointers { constexpr static Ptrs ptrs{ [](void* p) { delete static_cast\u0026lt;T*\u0026gt;(p); }, [](void* p)-\u0026gt;void*{ return new T{ *static_cast\u0026lt;T*\u0026gt;(p) }; } }; }; template\u0026lt;typename\u0026gt; struct Func; template\u0026lt;typename R, typename ...Args\u0026gt; struct Func\u0026lt;R(Args...)\u0026gt; { void* ptr = nullptr; const Ptrs* func_ptrs; R(*call_ptr)(void*, Args\u0026amp;\u0026amp;...); // needs to disallow same type, otherwise shadows the copy ctor... Also causes inifinite loops template\u0026lt;typename T, typename = std::enable_if_t\u0026lt;!std::is_same_v\u0026lt;Func, std::decay_t\u0026lt;T\u0026gt;\u0026gt;\u0026gt;\u0026gt; Func(T\u0026amp;\u0026amp; t) { ptr = new std::decay_t\u0026lt;T\u0026gt;(std::forward\u0026lt;T\u0026gt;(t)); func_ptrs = \u0026amp;TypePointers\u0026lt;std::decay_t\u0026lt;T\u0026gt;\u0026gt;::ptrs; call_ptr = [](void* p, Args\u0026amp;\u0026amp;... args) -\u0026gt; R { if constexpr(std::is_void_v\u0026lt;R\u0026gt;) { // the Args types are not deduced. This is not typical perfect-forwarding... (R)(*static_cast\u0026lt;std::decay_t\u0026lt;T\u0026gt;*\u0026gt;(p))(std::forward\u0026lt;Args\u0026gt;(args)...); } else { return (*static_cast\u0026lt;std::decay_t\u0026lt;T\u0026gt;*\u0026gt;(p))(std::forward\u0026lt;Args\u0026gt;(args)...); } }; } ~Func() { func_ptrs-\u0026gt;deleter_ptr(ptr); } R operator()(Args ...args) const { struct EmptyFunc{}; if (!ptr) throw EmptyFunc{}; return call_ptr(ptr, std::forward\u0026lt;Args\u0026gt;(args)...); } // copy Func(const Func\u0026amp; f) : ptr(f.func_ptrs-\u0026gt;copy_ptr(f.ptr)), func_ptrs(f.func_ptrs), call_ptr(f.call_ptr) {} // move Func(Func\u0026amp;\u0026amp; f) : ptr(f.ptr), func_ptrs(f.func_ptrs), call_ptr(f.call_ptr) { f.ptr = nullptr; } }; int main() { using std::cout, std::endl; int ans = 42; Func\u0026lt;int(char)\u0026gt; func{[\u0026amp;](char c){ return ans + c; }}; const auto func2 = std::move(func); cout \u0026lt;\u0026lt; func2(2) \u0026lt;\u0026lt; endl; Func\u0026lt;short(char)\u0026gt; f3 {func2}; // nested func cout \u0026lt;\u0026lt; f3(3) \u0026lt;\u0026lt; endl; } It\u0026rsquo;s a rough demo only, but you get the idea: \u0026ldquo;remember\u0026rdquo; how to do things later by storing function pointers.\nptr is the stored callable. func_ptrs is a group of function pointers, for managing stored callable of type T. call_ptr records how to call the type-erased callable.\nAnother implementation would be an abstract base functor, which defines the virtual operator() with desired return type and arg types. In fact we\u0026rsquo;ve just implemented something similar to vtables!\nPerformance The performance cost mainly stems from dynamic allocation and function pointer redirections.\nOwnership std::function has ownership over the contained callable. Since C++26, there is also std::function_ref which stores non-owning reference to the actual callable, to avoid additional allocation.\nstd::any As its name suggests, std::any is a container, that can wrap an object of any type. The type info is checked on access, so it provides type safety, compared to void*.\nBesides that, std::any has clear owning semantics, while void* pointers have no inherent ownership. Since the size of the object can be arbitary, it generally requires dynamic allocation (so it\u0026rsquo;s more expensive compared to std::variant).\nThe implementation of any_cast requires no RTTI, since std::any does not need to know the exact type of the contained object, it only needs to check if the requested type matches the actual type when doing any_cast. This is typically achieved by storing a pointer to a static member function of a class template that is instantiated by the stored type. Comparing types is thus equivalent to comparing pointers to templated functions.\nThat being said, std::any::type() is available for obtaining runtime typeinfo of the contained object (It does require RTTI, by storing type_info). This allows flexible visitation.\nstd::shared_ptr What has std::shared_ptr to do with type-erasure? Well, it stores the deleter and allocator type-erased, inside the shared control block, so it\u0026rsquo;s only templated by the object type.\nIn a typical implementation, shared_ptr holds only two pointers: one to the shared object, one to the \u0026ldquo;control block\u0026rdquo; that is also shared by all replicated instances. The control block will hold the pointer to the managed object (or the object itself), the deletor and the allocator (both are type-erased), and the ref-counting numbers.\nA generic deleter can be supplied during construction, then stored (type-erased) inside the control block.\nstd::variant A type-safe union. An instance of std::variant at any given time either holds a value of one of its alternative types, or in the case of error - no value.\nAs with unions, if a variant holds a value of some object type T, the object representation of T is directly within the object representation of the variant itself. Variant is not allowed to allocate additional (dynamic) memory. It\u0026rsquo;s usually implemented with placement new, on a buffer that is large enough to hold all kinds of elements, and has appropriate alignment. Or a tagged union.\nVisitation std::visit works on std::variant by taking a generic callable that can be applied to any type held by the variant object. If the visitor function is not exhaustive, you get a compile time error. This allows unified, type-safe operations on std::variant objects.\nImplementation A typical implementation can generate (at compile time) a table of function pointers to the resolved/instantiated function for every value type of the variant. At runtime, the stored type index is used to select the right function.\nAgain, function pointers!\nOther sum types std::optional, std::expected, \u0026hellip;\nIn general, sum types sits between actual type erasure that allows wrapping arbitary types at runtime, and fully static polymorphism.\nType-erased iterator E.g. boost::any_range, any_iter. Such iterators wraps any iterator that satisfy some behaviors, such as being forward iterators. They\u0026rsquo;re especially useful at API boundaries, to provide support for abitary iterator/ranges, without compile-time monomorphization.\n","date":"2023-07-11T00:00:00Z","permalink":"https://kya8.github.io/p/type-erasure-in-c-/","title":"Type erasure in C++"},{"content":"In most situations, the move constructor of a class in C++ can be made to not throw exceptions, given the Rule of 0/3/5 is respected. When Rule of 0 is followed, any non-trivial move operation should ultimately trace down to lowest-level resource-owning classes, and such classes are usually simple to move (e.g. copy a pointer), so their move ctors can be made noexcept.\nThe compiler-generated move-constructor for a class is implicitly noexcept, unless its base/member\u0026rsquo;s move-constructors are potentially throwing. If you forgot to make your own class\u0026rsquo;s move ctor noexecpt, or use a defaulted potentially throwing move ctor (because a member\u0026rsquo;s move ctor is throwing), then this property will pass on.\nWhy should we make the move ctors noexcept, besides \u0026ldquo;because we can\u0026rdquo;? Because failing to provide noexcept move ctors can be a missed optimization.\nstd::vector resize std::vector\u0026lt;T\u0026gt;::resize() will potentially relocate the elements, by move if possible, while providing strong exception safety guarantee:\nIf T\u0026rsquo;s move ctor is noexcept, then move the elements to new location. else, the move ctor is potentially throwing, and a nothrow copy ctor is available, the elements will be copied(!) else, use the throwing move ctor. The exception guarantee is waived. If T somehow is not nothrow movable, a potential full copy will be made when relocation happens!\nstd::deque std::deque will not relocate its elements, if push/pop happens at the front/end. So in most cases this is less of an issue.\nstd::function and SBO std::function implementations often employ small buffer optimization (SBO) in order to avoid dynamic allocation incurred by type erasure, if the size of the callable fits in.\nWithout SBO, std::function\u0026rsquo;s move constructor is trivial, you only move the (type-erased) pointer, so it\u0026rsquo;s always noexcept. However if SBO is in effect, the callable is stored inline so itself has to undergo move. If the callable is not nothrow movable, neither will be the std::function holding it.\nBefore ISO C++20, std::function\u0026rsquo;s move ctor is not marked noexcept.\nSome implementations will choose to disable SBO if the callable\u0026rsquo;s type is not nothrow movable, in order to provide strengthened noexcept move for std::function.\nfurther reading https://ibob.bg/blog/2018/07/03/compiler-generated-move https://quuxplusone.github.io/blog/2019/03/27/design-space-for-std-function/ ","date":"2023-06-25T00:00:00Z","permalink":"https://kya8.github.io/p/the-noexcept-move-constructor/","title":"The `noexcept` move constructor"},{"content":"Related resources Talks:\nHerb Sutter - Atomic Weapons Herb Sutter - Lock-Free Programming (or, Juggling Razor Blades) ","date":"2023-06-09T00:00:00Z","permalink":"https://kya8.github.io/p/c-concurrency-in-action/","title":"C++ Concurrency in Action"},{"content":"Brief recap on perfect forwarding Reference collapsing and type deduction There is no reference-to-reference types in C++: such type declarations would just collapse to a normal reference. Depending on the type of the reference, the final type is a lvalue-ref if one of the refs is lvalue-ref, otherwise a rvalue-ref.\nThe reference collapsing rule enables deduction of forwarding references:\n1 2 3 4 template\u0026lt;typename T\u0026gt; decltype(auto) func(T\u0026amp;\u0026amp; ...arg) { return func_inner(std::forward\u0026lt;T\u0026gt;(arg)...); } The type T will be either a value type w/o reference, or an lvalue-ref, such that the collapsed T\u0026amp;\u0026amp; type will match the value categories of arguments.\nstd::forward\u0026lt;T\u0026gt; It effectively returns T\u0026amp;\u0026amp; reference to its arguments. According to the rules of the value categories of function expressions, if T\u0026amp;\u0026amp; is rvalue-ref, the forward expression is itself an rvalue. Otherwise T\u0026amp;\u0026amp; was deduced to lvalue-ref, the forward expression is an lvalue. Therefore, std::forward always forward arguments as their original value categories.\nThe std::forward\u0026lt;T\u0026gt; function template is meant to be used within deduced contexts, i.e. where the type T has been deduced (either as a type template parameter T\u0026amp;\u0026amp;, or auto\u0026amp;\u0026amp;). You should NOT let it deduce T via its argument, this is not how it works!\nLuckily, the C++ standard specifies the signatures as T\u0026amp;\u0026amp; forward( typename std::remove_reference\u0026lt;T\u0026gt;::type\u0026amp; t ) and T\u0026amp;\u0026amp; forward( typename std::remove_reference\u0026lt;T\u0026gt;::type\u0026amp;\u0026amp; t ). This makes type deduction on T impossible, so using std::forward without specifying template parameter is a compile-time error.\nImperfect forwarding This title is somewhat clickbaity. Here we discuss some workarounds and unusual ways of using perfect forwarding.\nUse without templates Often we want a function to accept both rvalue and lvalue arguments. Sometimes we just write 2 separate definitions for this (e.g. move and copy constructor), because they\u0026rsquo;re rightfully different. However, these two overloads can sometimes be quite duplicated. To avoid code duplication:\nA quick-and-dirty approach is to always pass by value, then move. This incurs one additional move:\nFor the lvalue-ref overload, this means copy first, then move. For rvalue-ref overload, this means move twice. This method is acceptable when moving is cheap.\nAlways forward to an internal function template that takes forwarding reference, and let it deduce the type. Use std::forward\u0026lt;T\u0026gt; inside the function template. Since the function is only used internally, we don\u0026rsquo;t need to check its arg type.\nVariadic forward in init-capture Note: We\u0026rsquo;re talking about capturing by copy or move, not by reference.\nSince C++14, init-capture enables lambdas to capture (by value) by move, or by forwarding:\n1 2 3 4 // within some template that deduces T [val = std::forward\u0026lt;T\u0026gt;(val)]{ // ... }; This only works one-by-one. What if we want to forward a parameter pack?\nWith C++20, it\u0026rsquo;s simple:\n1 [...vals = std::forward\u0026lt;Ts\u0026gt;(vals)]{} //... Before C++20, tuples are your friend: (perfectly) forward the parameter pack into a tuple, then unpack the tuple inside the lambda:\n1 2 3 4 5 6 [vals = std::make_tuple(std::forward\u0026lt;Ts\u0026gt;(vals)...)] { // use the vals, via std::apply: std::apply([](auto\u0026amp;\u0026amp; ...args){ // use args as you want }, vals); }; std::make_tuple will make a by-value tuple, initialized by forwarding the vals. We unpack the tuple with std::apply.\nUse in non-deduced context Although std::forward is designed for deduced contexts, it can sometimes be useful in non-deduced scenarios.\nFor example, the R operator()(Args... args) of std::function\u0026lt;R(Args...)\u0026gt; effectively does INVOKE\u0026lt;R\u0026gt;(f, std::forward\u0026lt;Args\u0026gt;(args)...), where f is the stored callable. We known that the Args is specified by the user, not deduced. However, it still makes sense to forward args... with std::forward\u0026lt;Args\u0026gt;:\nIf some Arg has some value type, then the operator() receives it by value. Inside operator(), we do want to pass it as an rvalue. If Arg has rvalue/lvalue type, then the additional forwarding has no effect. ","date":"2023-05-30T00:00:00Z","permalink":"https://kya8.github.io/p/imperfect-forwarding/","title":"(Im)perfect forwarding"},{"content":"Semantic const Imagine we have a class with some getter/observer method that is protected by a mutex:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class DataWrapper { private: DataType data_; std::mutex mtx_; //... public: DataType getData(); //... }; DataType DataWrapper::getData() { std::scoped_lock lk(mtx_); return data_; } The lock operation on the mutex cannot work on a const *this, so the getData() method cannot be made const. This contradicts our usual assumption of a getter method, how can an observer be non-const?\nAfter all, the non-constness comes from the implementation of getData(), which requires locking the mutex, thus modifying one of the members. However, the interface being non-const is still suboptimal. What if we implement getData() with std::atomic\u0026lt;T\u0026gt;::load, which is const? The interface declaration should be orthogonal to implementation details.\nIf we insist on keeping the mutex as a direct data member, the solution is to mark mtx_ as mutable, so it\u0026rsquo;s mutable even with const *this. This way, we achieve semantic const, so the user of the API can hold their usual assumptions.\nconst overloading Const overloading is mostly used when returning a reference/pointer to some data within(or managed by) an object. An example is the operator[] of std::vector, which returns const reference when the vector itself is const, or non-const reference otherwise.\nFor std::vector, the const overload is semantic only. Because, it\u0026rsquo;s perfectly valid to return a pointer to non-const value, that is managed by a const std::vector ref. However, since std::vector is a standard container type that manages data on its own, we want it to have value semantics: If the vector is const, so should be the elements managed by it.\nAvoid code duplication When you starting providing const overloads, you\u0026rsquo;ll likely run into lots of duplicated code, for the const and non-const overloads.\nWe can re-use the const methods in the non-const overload, by forcing constness on *this, and returning the result as mutable reference. For the former we have std::as_const. Below is an implementation of as_mut (Sorry, I took the nomenclature from Rust):\n1 2 3 4 5 6 7 8 template\u0026lt;typename T\u0026gt; constexpr auto\u0026amp; as_mut(T\u0026amp; t) noexcept // T can be const or non-const { return const_cast\u0026lt;std::remove_const_t\u0026lt;T\u0026gt;\u0026amp;\u0026gt;(t); } // This overload disallows any rvalue argument template\u0026lt;typename T\u0026gt; void as_mut(const T\u0026amp;\u0026amp;) = delete; Semantic non-const Sometimes things go the opposite direction: A method modifies some internal state via a pointer/reference member, so it only requires const *this, e.g. in a PIMPL class. In such circumstances, we still might want to mark the method as non-const, when the object actually owns the referenced data, since the managed data is semantically part of the object itself.\nconst views, shallow constness However, if the object is merely a non-owning view into some referenced data, it makes more sense to use \u0026ldquo;shallow\u0026rdquo; constness, i.e. the underlying data is mutable through a const view object. std::span\u0026lt;T\u0026gt; is one example of shallow constness.\n","date":"2023-05-19T00:00:00Z","permalink":"https://kya8.github.io/p/semantic-const/","title":"Semantic const"},{"content":"The const problem In many cases, we want to define a variable that is complex to initialize. Often, this is done like the following:\n1 2 3 4 5 int some_var; { // complex code to fill the final value of some_var } // from now on, some_var should not be modified This forbids the use of const on the variable without creating another intermediate variable. Also, this cannot be used in member initialization lists in a constructor definition.\nThis is often the primary obstacle when enforcing const-correctness.\nAn obviously solution is to define a function dedicated for the complex initialization process. And this is indeed the right direction if this subroutine is used at multiple places. Otherwise, an IIFE is preferred:\n1 2 3 const auto some_var = [\u0026amp;]()-\u0026gt; int { // do whatever, optionally use outer variables. }(); The in-place lambda invocation can always be inlined, so it shouldn\u0026rsquo;t affect performance. This pattern also captures surrounding states seamlessly: If we were to use a dedicated function, all states required for initialization have to be passed via function parameters.\nThe ternary operator When the initialization is only dependent on a runtime binary condition, The ternary operator also works, and is more concise than an IIFE.\nHowever they\u0026rsquo;re not equivalent, in case we\u0026rsquo;d like to make use of a compile time condition:\n1 2 3 4 5 6 7 constexpr bool cond = TRUE_OR_FALSE; const auto i1 = cond? 0 : 1; const auto i2 = [\u0026amp;] { if constexpr (cond) return \u0026#34;i\u0026#39;m a string\u0026#34;; else return 42; } const auto i3 = cond? \u0026#34;i\u0026#39;m a string\u0026#34; : 42; // does not compile. i1 is an int; i2 will be either const char* or int depending on cond. i3 will simply fail to compile. That\u0026rsquo;s because the ternary expression takes a runtime condition, it\u0026rsquo;s equivalent to an IIFE with plain if else branches.\nIn generic code, where the resultant type can depend on some compile time condition, use IIFE with if constexpr.\nFor control flow Sometimes it\u0026rsquo;s just convenient to be able to use return for control flow, e.g. to avoid goto. If the return type is void, it\u0026rsquo;s equivalent to a do {...} while(0) block.\nTurn statements into expression As you can see, IIFE is particularly useful for converting a series of statements into an expression. (Well, normally we\u0026rsquo;ll have to wrap them inside another function. IIFE just spares us from writing a separate function for this purpose.)\nIIFE provides a generic way to wrap statements into expression (more generic than using ternary expressions and comma operator), and use it where only expressions are allowed, e.g. in comma fold expressions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 template\u0026lt;class ...Ts\u0026gt; void f(Ts\u0026amp;\u0026amp;... arg) { ([\u0026amp;] { if constexpr (std::is_same_v\u0026lt;std::decay_t\u0026lt;Ts\u0026gt;, std::string\u0026gt;) { std::cout \u0026lt;\u0026lt; \u0026#34;!!!NextWeHaveAString!!!:\u0026#34;; } std::cout \u0026lt;\u0026lt; std::forward\u0026lt;Ts\u0026gt;(arg) \u0026lt;\u0026lt; \u0026#34;, \u0026#34;; }(), ...); } int main() { f(1.0, 2, std::string(\u0026#34;abc\u0026#34;)); } Everything is an expression! This emulates e.g. block expressions in Rust.\nUse with std::optional There\u0026rsquo;s another hidden spot in the const problem: What if some_var should not be initialized at all? E.g., depending on the condition, some_var might become meaningless, so we should not define it at all.\nThis is a common pattern that plagues C++ programs:\n1 2 struct SomeComplexStruct var; // default initialized... const bool init_success = init_complex_struct(var); if init_success is false, var shouldn\u0026rsquo;t be there at all. However we\u0026rsquo;re left with a zombie variable that is default-initialized.\nThis is a much broader topic regarding RAII and class invariants, and there\u0026rsquo;re many solutions/opinions to it, including using throwing constructors, factories that returns nullable pointers/values. For the purpose of this article, we could use an IIFE that returns an std::optional, and check for null on the result.\n","date":"2023-05-15T00:00:00Z","permalink":"https://kya8.github.io/p/iife-in-c-/","title":"IIFE in C++"},{"content":"The fork(2) syscall This is one of the identifying features of a Unix-like operating system. fork(2) has existed since the first version of Unix back in the days of PDP-11. It creates a new process by simply duplicates the entire address space of the calling process, after which point they run indenpendently.\nfork+exec is the standard way to create a child process in Unix, although it has an obvious problem: The parent process will have its entire process space copied, only to spawn a new process that has little regard for any of it. In fact, this is what the First Edition Unix did.\nThe virtual memory story Overtime, people got smart and started implementing Copy-On-Write for fork, so it din\u0026rsquo;t need to actually copy that much pages. In the case of fork+exec, no extra segments will be copied. This is the most prominent reason for defending fork: The OS only copies when needed! Nothing is wasted.\nIndeed, the CoW approach did solve some of fork\u0026rsquo;s problems, but not all. In particular, The file descriptor inhertance from fork isn\u0026rsquo;t nice to play with, and has lead to many hacks (such as CLOEXEC). Not only that, this model has implicitly lead to memory overcommittment and the OOM killer on Linux, which IMO is one of the most glaring design failures on Linux.\nThe OOM killer Support we have 8G of memory in total, and some process has taken-up 6G of it (e.g., by malloc and memset). Now this process calls fork to create a new child process. We all know that will not fail on Linux. What if the calling process merely wants to fork and exec a new process? The 2G remaining memory is more than enough for it. After all, it is the obvious point for CoW implementations of fork which we all agree upon.\nThere\u0026rsquo;s no way for the OS to know how the child process will be used after fork. It may exec a tiny program and exit immediately, or it might actually fiddle with all the \u0026ldquo;copied\u0026rdquo; data. The CoW implementation is reponsible for keeping this transparent, so everyone is happy. That is, until the child process starts modifying more than 2G of memory and get killed by OOM!\nBy CoW fork and overcommittment, the Linux kernel essentially lies to the child process that it has allocated 6G of memory, while effectively it can write to only 2G of it (given the parent process does not release its memory). The child is free to use that 6G of memory however it wants, but there\u0026rsquo;s no guarantee it won\u0026rsquo;t exhaust all available memory and get killed. Maybe the parent process will release its hold of memory at some point, so the lie is covered up. Who knows! Most user-land processes, might get killed by OOM, essentially at any point, because the kernel lies to user-land processes about memory reservations.\nThere are some other examples of memory overcommittment, e.g. malloc, but that is a different story.\nAlternatives vfork and clone The vfork syscall was an early alternative to fork, first appearing on BSD. It\u0026rsquo;s essentially a restricted version of fork.\nA more functional alternative would be clone on Linux. From man 2 clone:\nBy contrast with fork(2), these system calls provide more precise control over what pieces of execution context are shared between the calling process and the child process\u0026hellip;\nspawn The obvious solution is the spawn model, where a new process is constructed from a clean state. The user only opts in for some inheritance or shared state, so it has none of the flaws of fork.\nA somewhat failed attemp is posix_spawn defined by POSIX standard. Essentially no one uses it since it\u0026rsquo;s far too cumbersome.\nIf implemented correctly, spawn should be preferable to fork in most cases. The fork model can be genuinely useful in some contexts, however most of time people just fork and exec to create child processes, which gave birth to its shortcomings.\n","date":"2023-02-16T00:00:00Z","permalink":"https://kya8.github.io/p/fork2-and-the-oom-killer/","title":"Fork(2) and the OOM killer"},{"content":"The rule of 0/3/5 A C++ class that manages some non-RAII resource/object (e.g., FILE*) would require a user-defined dtor. Also, such resource generically cannot be copied plainly. Most of the time, this either disallows copying, or requires special handling.\nSuch classes are direct (i.e. it doesn\u0026rsquo;t contain another RAII wrapper object), exclusive resource managers.\nOn the other hand, if a class is not one of such classes, it should not have custom destructors, copy/move constructors or copy/move assignment operators. Let RAII do its thing! Only the lowest-level resource manager classes (where all the special handling actually happens) would need those.\nWith these in mind, the rule of 0/3/5 becomes obvious:\nRule of three If a class requires a user-defined destructor, a user-defined copy constructor, or a user-defined copy assignment operator, it almost certainly requires all three! Because it certainly manages some non-RAII resource handle, otherwise it wouldn\u0026rsquo;t require those.\nRule of zero Classes that have custom destructors, copy/move constructors or copy/move assignment operators should deal exclusively with ownership (which follows from the Single Responsibility Principle). Other classes should not have custom destructors, copy/move constructors or copy/move assignment operators.\nThis rule also appears in the C++ Core Guidelines: If you can avoid defining default operations, do.\nRule of five Because the presence of a user-defined destructor, copy-constructor, or copy-assignment operator prevents implicit definition of the move constructor and the move assignment operator, any class for which move semantics are desirable, has to declare all five special member functions.\nUnlike Rule of Three, failing to provide move constructor and move assignment is usually not an error, but a missed optimization opportunity.\n","date":"2023-01-18T00:00:00Z","permalink":"https://kya8.github.io/p/rule-of-0/3/5/","title":"Rule of 0/3/5"},{"content":"Pointer arithmetics It is well-known that in both C and C++, pointer arithmetics is only meaningful for operands (and the imaginary resultant pointer address) that are related to each other. By related we mean, they both point to the same object (or one-past-end), or the same array (or one-past-end).\nPer C++ standard, pointers are iterators, not numbers representing address space, although they\u0026rsquo;re often implemented as such.\nTo quote https://stackoverflow.com/a/56038995/17815599:\nSpeaking more academically: pointers are not numbers. They are pointers.\nIt is true that a pointer on your system is implemented as a numerical representation of an address-like representation of a location in some abstract kind of memory (probably a virtual, per-process memory space).\nBut C++ doesn\u0026rsquo;t care about that. C++ wants you to think of pointers as post-its, as bookmarks, to specific objects. The numerical address values are just a side-effect. The only arithmetic that makes sense on a pointer is forwards and backwards through an array of objects; nothing else is philosophically meaningful.\nSo, p1 - p0 isn\u0026rsquo;t really saying \u0026ldquo;give me the difference between the addresses pointed by p1 and p0\u0026rdquo;, it\u0026rsquo;s saying \u0026ldquo;Assuming they both refer to objects in the same array, what\u0026rsquo;s the difference between their indices inside the array?\u0026rdquo; (Here, we consider a single object as an array of length one). If the assumption does not hold, this is undefined behavior. For relational (greater than, less than\u0026hellip;) comparisons however, the behavior is unspecified.\nwhat are \u0026ldquo;arrays\u0026rdquo;? It covers a bit wider than normal (i.e. int arr[]) arrays. In particular, pointer returned by malloc can be addressed as arrays.\nAlso see https://stackoverflow.com/questions/47830449/can-you-do-arithmetic-on-a-char-pointing-at-another-object for aliasing char* pointers.\npointer to struct member 1 2 3 4 5 6 7 struct xyz_s { float x, y, z; }; xyz_s pt; auto px = \u0026amp;pt.x; auto py = px + 1 // ??? xyz is standard-layout type, which means it has C-like memory layout. However in this example, even if the struct xyz_s does not contain any paddings, py does not actually point to pt.y. It points to \u0026ldquo;one-past-end\u0026rdquo; of pt.x! That\u0026rsquo;s because there\u0026rsquo;re no arrays here, so py can only be the \u0026ldquo;one-past-end\u0026rdquo; pointer of pt.x. Although evaluating px+1 is well-defined, dereferencing the resultant py is UB. It\u0026rsquo;s not pt.y!\nIf we change xyz_s to contain an array of 3 floats, that kind of pointer arithmetic is okay. Also absence of padding in array is guaranteed.\nPadding Actually, the compiler is free to insert paddings inside a struct in an implementation-defined way, except at the beginning of a struct. There\u0026rsquo;s nothing in the standard mandating no paddings in xyz_s!\nThis is also why there\u0026rsquo;s no guaranteed size for std::array\u0026lt;T, N\u0026gt;. Even if it only contains a single member T data_[N], the compiler can still insert paddings after it.\npointer in nested arrays 1 2 3 4 5 struct Pt3 { float xyz[3]; }; std::vector\u0026lt;xyz_s\u0026gt; vec(N); auto p0x = \u0026amp;vec[0].xyz[0]; auto p0z = p0x + 2; // okay auto p1x = p0z + 1; // bad Here, p1x is still one-past-end of vec[0].xyz[2]. Because, there\u0026rsquo;s no array of type float and length N*3! And consider possible paddings mentioned above.\nPointer to first member of (standard layout) struct (By \u0026ldquo;first\u0026rdquo; we mean the first declared member)\nRef: https://en.cppreference.com/w/cpp/language/static_cast#Pointer-interconvertible_objects\nTwo objects a and b are pointer-interconvertible if:\nthey are the same object, or one is a union object and the other is a non-static data member of that object, or one is a standard-layout class object and the other is the first non-static data member of that object or any base class subobject of that object, or there exists an object c such that a and c are pointer-interconvertible, and c and b are pointer-interconvertible. \u0026hellip;combined with pointer conversion rules, it\u0026rsquo;s possible to convert between pointer to a standard-layout struct and pointer to its first member, via an intermediate void* pointer.\nPointer total order There is actually one exception to the \u0026ldquo;same-object-or-array\u0026rdquo; rule: the total order of pointers in C++. It only applies to comparison functors, std::less, std::greater etc. This total order is consistent with defined pointer comparison rules of the built-in comparison operators. For the unspecified case, the result becomes implementation-defined.\nNote that in C, relational comparison of unrelated pointers is undefined.\n","date":"2023-01-04T00:00:00Z","permalink":"https://kya8.github.io/p/pointers-again/","title":"Pointers (again)"},{"content":"Problem with private 1 2 3 4 5 6 class MyClass { private: /* internal implementation details */ public: /* public stuff meant to be exported */ }; Problems:\nprivate stuff included in header, breaking encapsulation Undesired disclosure for proprietary projects Additional headers needed by private stuff, are included in header Some 3rd-party headers do funky things Increased compilation time Breaks ABI, since whenever private changes, the class ABI might change as well Using functions C allows true encapsulation via opaque struct pointers. But what if I still want to use classes?\nEnter PIMPL Short for Pointer to Implementation\nThe header file would look like:\n1 2 3 4 5 6 7 8 9 10 11 class MyClass { public: // public methods go here ~MyClass() noexcept; // required MyClass(/* args to forward to Impl... */); private: struct Impl; std::unique_ptr\u0026lt;Impl\u0026gt; pimpl; } The actual implementation class MyClass::Impl is only forward-declared in the header. This requires us to forward-declare the destructor of MyClass, otherwise the compiler generated definition will attempt to call the dtor of Impl, which is not declared in this header.\nThe source file:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 struct MyClass::Impl { // define the actual members here. Impl(/* args... */) { // ... } ~Impl() noexcept; // define it } MyClass(/* args... */) : pimpl(std::make_unique\u0026lt;Impl\u0026gt;(/* args... */)) {} // always use make_unique ~MyClass() noexcept = default; // methods for public class void MyClass::someMethod() { // use pimpl-\u0026gt;... } Always use unique_ptr and std::make_unique for PIMPL. DO NOT use a raw (or even void*) pointer!\nCopyable PIMPL class PIMPL classes are already move-able for free, because the unique_ptr is move-able. To copy the actual Impl object, the new MyClass object should copy-construct its pimpl member, provided the Impl class is itself copyable.\n1 2 // should be declared in the header first... MyClass(const MyClass\u0026amp; rhs) : pimpl(std::make_unique\u0026lt;Impl\u0026gt;(*rhs.pimpl)) {} Comparison with C++20 modules ","date":"2022-12-03T00:00:00Z","permalink":"https://kya8.github.io/p/the-pimpl-idiom/","title":"The PIMPL idiom"},{"content":"Emulating ARM machines on QEMU hasn\u0026rsquo;t been straight-forward due to lack of a standardized way to configure the bootloader across different ARM boards. One had to extract the kernel image, and specify the boot options on the command line (-kernel, -initrd), so QEMU knows what to do with its machine-specific boot code.\nWe can make things easier with the help of UEFI (namely EDK2, with ARM support), so installing and booting Linux just works like on a x86 PC target.\nPrerequisites QEMU system emulator for ARM. EDK2 binaries for ARM. They can be extracted from the debian package qemu-efi-arm or qemu-efi-aarch64, depending on your target arch. Official Debian installer iso for ARM. Booting the installer NOTE: This example is for arm32\nFirst of all, create a new disk image via qemu-img. Copy EDK2 FW binaries (AAVMF32_CODE.fd and AAVMF32_VARS.fd, the latter is for hosting volatile variables) and the installer image to the same directory.\nWe will be emulating the virt board, which has support for virtio devices.\n1 2 3 4 5 6 7 qemu-system-arm -M virt -m 512M -cpu cortex-a15 -smp 4 \\ -device qemu-xhci -device usb-kbd \\ -device usb-storage,drive=install -blockdev file,filename=debian-testing-armhf-DVD-1.iso,node-name=install \\ -blockdev qcow2,node-name=root,file.driver=file,file.filename=disk0.qcow2 -device virtio-blk-device,drive=root \\ -nic user,model=virtio \\ -pflash ./AAVMF32_CODE.fd -pflash ./AAVMF32_VARS.fd \\ -device ramfb The system is given 512M of RAM and 4 cpus (depending on your QEMU version, this could mean either 4 sockets or 4 cores), the CPU capability is set to cortex-a15. -device qemu-xhci -device usb-kbd attaches a low-overhead USB XHCI bus, and a USB keyboard. You could add a mouse if needed. Alternatively, on-board USB support that comes with virt is available by passing -usb. Next two lines attach the installer iso as a USB storage device, and the rootfs disk as a virtio block device. -nic user,model=virtio enables basic user-mode networking, backed by the virtio NIC. -device ramfb adds a simple display device, which is just a frambuffer in guest memory. QEMU ARM system emulator does not emulate a display device by default. The standard std VGA won\u0026rsquo;t work since the installer environment lacks required DRM kmods. The graphics \u0026amp; input part can be left-out (with -nographic), in which case the installer will be presented on the serial console.\nThe guest will now boot into the installer iso. Simply follow the installation instructions, the grub-efi bootloader will be installed to the EFI firmware automatically.\nBooting the installed system No additional configuration is required. Don\u0026rsquo;t forget to attach the UEFI firmware via -pflash.\n1 2 3 4 5 6 7 qemu-system-arm -M virt -m 512M -cpu cortex-a15 -smp 4 \\ -device qemu-xhci -device usb-kbd \\ -blockdev qcow2,node-name=root,file.driver=file,file.filename=disk0.qcow2 -device virtio-blk-device,drive=root \\ -nic user,model=virtio,hostfwd=tcp::2345-:22 \\ -pflash ./AAVMF32_CODE.fd -pflash ./AAVMF32_VARS.fd \\ -device VGA -virtfs local,path=/host/path/to/shared/,id=share,mount_tag=share,security_model=mapped There are a few additional configurations:\nHost porting forwarding is enabled for host port 2345, to guest port 22. This way we are able to ssh directly into the guest system. Attach a shared folder to the guest, backed by 9pfs. The folder can be mounted in the guest via mount -t 9p -o trans=virtio share /path/to/mount Voilà! Your new virtual ARM system is ready to go!\n","date":"2021-07-28T00:00:00Z","permalink":"https://kya8.github.io/p/emulating-arm-on-qemu-with-uefi/","title":"Emulating ARM on QEMU, with UEFI"}]